{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pNfoXODGq4TV"
   },
   "source": [
    "## Assignment 3: Spark\n",
    "Name: Bruno C. Gonzalez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMr5xQgIq4TX"
   },
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "In this assignment, you will do the following:\n",
    "\n",
    "* Import a dataset into the Databricks Spark environment\n",
    "\n",
    "* Create tables for the data imported\n",
    "\n",
    "* Perform basic data analysis using transformations and Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GgvpSXx_q4TX"
   },
   "source": [
    "**Questions** (12 marks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. Explain the main differences between RDDs, Dataframes and Datasets (4 marks)\n",
    "*Answer:*\n",
    "*The RDDs was the primary user-facing API in Spark since its inception  and are defined as the distributed collection of the data elements without any schema. The Dataframes is  an immutable distributed collection of data organized into named columns. The Dataset is an extension of the Dataframe with more added features like type-safety and strongly-typed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "\n",
    "2. Answer the following questions:\n",
    "\n",
    "2.1 How many sensor pads are reported to be from Poland (2 marks)\n",
    "\n",
    "*Answer:*\n",
    "*12,744*\n",
    "\n",
    "2.2 How many different LCDs (distinct colors) are present in the dataset (2 marks)\n",
    "\n",
    "*Answer:*\n",
    "*3*\n",
    "\n",
    "2.3 Find 5 countries that have the largest number of MAC devices used (2 marks)\n",
    "\n",
    "*Answer:*\n",
    "\n",
    "| Country | Count |\n",
    "|-------------------|-------|\n",
    "| United States     | 70405 |\n",
    "| China             | 14455 |\n",
    "| Japan             | 12100 |\n",
    "| Republic of Korea | 11879 |\n",
    "| Germany           | 7942  |\n",
    "\n",
    "\n",
    "2.4 Propose and try an interesting statistical test or machine learning model you could use to gain insight from this dataset. Note, you don't have to use Machine Learning for this question. You can apply any analysis to the data even using SparkSQL, Python visualization libraries to analyze the data. Another example cloud be to apply correlation functions or other Spark functions to analyze the data. (2 marks)\n",
    "\n",
    "*Answer:*\n",
    "\n",
    "Summary table\n",
    "\n",
    "\n",
    "|summary|     battery_level|         c02_level|       device_id|          humidity|          latitude|   lcd|          longitude|              temp|\n",
    "|-------|------------------|------------------|----------------|------------------|------------------|------|-------------------|------------------|\n",
    "|  count|            198164|            198164          198164|            198164|            198164|198164|             198164|            198164|\n",
    "|   mean|4.4997|1199.7639|         99082.5|                null| 61.9921|36.5211|-0.6459|22.0127|\n",
    "| stddev|2.8733| 231.06|57205.1637|                null|21.6723|17.9077|  88.7275| 7.2098|\n",
    "|    min|                 0|               800|               1|                25|            -51.75| green|             -175.0|                10|\n",
    "|    25%|                 2|              1000|           49522|                43|             35.69|  null|             -87.69|                16|\n",
    "|    50%|                 5|              1199|           99092|                62|              38.0|  null|               4.89|                22|\n",
    "|    75%|                 7|              1400|          148629|                81|              47.0|  null|             100.52|                28|\n",
    "|    max|                 9|              1599|          198164|                99|              72.0|yellow|             178.42|                34|\n",
    "\n",
    "\n",
    "Temperature by country\n",
    "![](temp_barchart.png)\n",
    "\n",
    "Correlation humidity and temperature:\n",
    "\n",
    "$-0.001$ There's no correlation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 3_v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
