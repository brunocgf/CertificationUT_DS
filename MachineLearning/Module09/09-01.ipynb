{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GjflwbWmfERQ",
    "toc-hr-collapsed": true
   },
   "source": [
    "<font size=\"6\"><b>Module 9 Part 1: TensorFlow Overview</b></font>\n",
    "\n",
    "In Part 1 of this module, we will introduce you to the popular [**TensorFlow**](https://www.tensorflow.org/) library used for intensive computing purposes. We will be going over the basic nuances and appropriate syntax of working with TensorFlow's Python API. \n",
    "\n",
    "In Part 2, we will be using the TensorFlow API to develop some basic machine learning models, which will lay the foundation to begin working with Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Kkh45LifERR"
   },
   "source": [
    "<font size=\"6\">Table of Contents</font>\n",
    "\n",
    "- 1 Introduction\n",
    "    - 1.1 Learning Objectives\n",
    "    - 1.2 Reading and Resources\n",
    "    - 1.3 Setup Notes\n",
    "- 2 What is TensorFlow?\n",
    "    - 2.1 How TensorFlow works\n",
    "    - 2.2 TensorFlow Benefits\n",
    "- 3 Graphs\n",
    "    - 3.1 Creating a basic graph\n",
    "    - 3.2 Basic mathematical operations\n",
    "    - 3.3 Exercise\n",
    "- 4 Sessions\n",
    "- 5 Placeholders & feed_dict\n",
    "- 6 Variables & Initialization\n",
    "    - 6.1 Variable Initialization\n",
    "    - 6.2 Variable Assignment\n",
    "    - 6.3 Exercise\n",
    "- 7 Names and Scopes\n",
    "- 8 Saving & Loading Graphs\n",
    "    - 8.1 Saving Graphs\n",
    "    - 8.2 Loading Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sLzVhvWwfERR",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2LzcWKvEfERT"
   },
   "source": [
    "## Learning Outcomes\n",
    "In this module, you will develop the knowledge and skills to use TensorFlow (TF) Python API. This will include:\n",
    "- Constructing and manipulating TensorFlow graphs (i.e., adding and inspecting nodes and operations of all types)\n",
    "- Running graphs and evaluating tensors in TensorFlow sessions\n",
    "- Building simple TF models and implementing TF optimizers \n",
    "- Visualizing graphs and model training progress\n",
    "\n",
    "There is a lot to tackle here, so this module will be separated into two parts:\n",
    "- Part 1 - TensorFlow Overview\n",
    "- Part 2 - Developing Models with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZRDWZIPsfERT"
   },
   "source": [
    "## Readings and Resources\n",
    "We invite you to further supplement this notebook with the following recommended texts/resources.\n",
    "\n",
    "  Géron, A. (2017). Chapter 9: Up and Running with TensorFlow and Chapter 10: Introduction to Artificial Neural Networks in *Hands-On Machine Learning with Scikit-Learn and TensorFlow* O’Reilly Media http://shop.oreilly.com/product/0636920052289.do![image.png](attachment:image.png)\n",
    "  \n",
    "  TensorFlow documentation and tutorials: https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gMF2ExBKfERU"
   },
   "source": [
    "## Setup Notes\n",
    "\n",
    "TensorFlow is available as a Python library (which is the implementation we will be using here). Hence, it must be installed into your Python package directory before it can be used. This can easily be done using the appropriate Python package installer (i.e. `pip`, `conda`). For more details on configuring TensorFlow onto your machine, please review the official documentation on installation: [**install TensorFlow**](https://www.tensorflow.org/install).\n",
    "\n",
    "Note that we will not be dealing with GPUs (graphics processing units) or TPUs (tensor processing units) in this course. You should not have to configure a container (i.e. Docker) to run TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tTnqLZ8ofERU",
    "toc-hr-collapsed": true
   },
   "source": [
    "# What is TensorFlow?\n",
    "\n",
    "Machine learning (ML) is a complex discipline. That said, building and implementing ML models is now significantly less daunting now than it used to be, largely thanks to sophisticated machine learning frameworks such as Scikit-learn (sklearn) and [**TensorFlow (TF)**](https://www.tensorflow.org/). While sklearn has become extremely popular for more traditional machine learning techniques, **TensorFlow has become the dominant framework for the development of Neural Networks.** As such, TF is essential for anyone looking to develop an expertise in Neural Networks and Deep Learning, and will thus be the focal point of modules 9, 10 and 11.\n",
    "\n",
    "TensorFlow is an open-source programming library reserved for high-demand numerical computation. It was originally developed by members of the Google Brain team for internal Google use, but later released under the *Apache 2.0 open-source license* near the end of 2015. Currently, it is considered ideal for large-scale machine learning applications as it was built with highly optimized C++ code and computational graph architecture, allowing for efficient parallelization (which is essential for training complex with lots of data). As a result, TensorFlow has made its way to become the tool of choice for many machine learning and deep learning practitioners. It also serves as the backbone for many popular neural network APIs such as Keras.\n",
    " \n",
    "TensorFlow can train and run deep neural networks for image recognition, object detection, machine translation, and all other kinds of sophisticated and complicated deep learning models. Perhaps most importantly, TensorFlow supports production prediction at scale, with the same models used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LzqYeqxdfERV"
   },
   "source": [
    "## How TensorFlow works\n",
    "TensorFlow allows developers to create **dataflow graphs**, which are essentially structures that describe how data moves through a graph, or a series of processing nodes. Each node in the graph represents a mathematical operation, and each connection or edge between nodes is a multidimensional data array, or tensor (this will be discussed in more detail in the next section). \n",
    "\n",
    "TensorFlow provides all of this for the programmer by way of a simple and relatively intuitive Python API; nodes and tensors (discussed shortly) in TensorFlow are Python objects, and TensorFlow applications are themselves Python applications. This provides the developer a quick and easy way to construct and test sophisticated models within a short period of time. \n",
    "\n",
    "However, it is important to note that the actual **math operations are not performed in Python**. The libraries of transformations that are available through TensorFlow are written as high-performance C++ binaries. **Python just directs traffic between the pieces, and provides simple and high-level programming abstractions to connect all of the pieces.**\n",
    "\n",
    "TensorFlow applications can be run on pretty much any platform or machine: your local computer, iOS and Android devices, a cluster in the cloud, CPUs or GPUs. If you use Google’s cloud platform, you can even run TensorFlow on Google’s custom TensorFlow Processing Unit (TPU) for even greater processing speed. That said, **regardless of what machine you use to train your model, the resulting models created can be deployed on almost any device with a proper TensorFlow installation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nuA20vqPfERW"
   },
   "source": [
    "## TensorFlow benefits\n",
    "The single greatest benefit TensorFlow provides for Neural Network model development is abstraction. The relatively simple API allows the developer to focus on the overall logic of their application, rather than getting bogged down by the nitty-gritty details of implementing complex neural network architectures. **Many deep learning libraries like Keras also leverage TensorFlow in the backend to make the process of developing complex models even simpler.**\n",
    "\n",
    "Perhaps equally important is TensorFlow's graph-based architecture, which makes parallel processing across multiple CPUs or GPUs fairly simple (at least from the developer's standpoint). TensorFlow also supports distributed computing, so you can train colossal neural networks on humongous training sets in a reasonable amount of time by splitting the computations across hundreds of servers. In fact, **TensorFlow can train a network with millions of parameters on a data set composed of billions of instances with millions of features each.**\n",
    "\n",
    "In addition, TensorFlow offers additional conveniences for developers who need to debug and gain introspection into TensorFlow apps. The TensorBoard visualization suite (which will be discussed in the next section of this module) lets you inspect and profile the way graphs run by way of a simple interactive, web-based dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mBAv167fERW",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Graphs\n",
    "\n",
    "TensorFlow differs from the typical programming library in the sense that its entire architecture is based on a type of computational abstraction known as a **computation graph**. This abstraction (also known as a **dataflow graph**) is used to represent user-defined computations through individual TensorFlow operations (also known as *ops*). This differs from standard programming conventions where one uses predefined operations to perform calculations. In a TF graph, we explicitly give the graph instructions on *how* to proceed with a calculation rather than *what* to calculate.\n",
    "\n",
    "A computation graph is composed of two major components:\n",
    "1. **Nodes** <br/>\n",
    "    Nodes are used to represent units of computation (i.e. analogous to mathematical operations). These are typically stored as a set of `tf.Operation` objects.\n",
    "\n",
    "2. **Edges** <br/>\n",
    "    Edges are used to represent the data consumed or produced by a computation (that is, the *input* or *output* of a `tf.Operation` respectively). These are stored as `tf.Tensor` objects.\n",
    "    \n",
    "**NOTE:** Refer to the TensorFlow Python API (https://www.tensorﬂow.org/api_docs/python/) for an alphabetized list of all TensorFlow symbols and their descriptions.\n",
    "\n",
    "For those familiar with graph theory, one can associate the *nodes* of the graphs to be the computational operations and the *edges* of the graphs to be the value(s) linked between operations. For example, consider the `tf.matmul` operation which is the matrix multiplication operation implemented in TensorFlow. Suppose we construct a graph using `tf.matmul`. One could expect this operation to translate to a single node with three associated edges (two incoming edges allocated for the matrices to be multiplied, and an outgoing edge for the calculated result).\n",
    "\n",
    "Below is a simple visualization of the example above. Note that the arrows on the edges indicate the direction the data will flow (differentiating between the incoming and outgoing edges). Furthermore, the ellipsis points are used here to indicate any other preceding or following operations that are also within the graph.\n",
    "\n",
    "<div style=\"text-align:center;margin:15px;\">\n",
    "<img src='Module 9 images/vdiagram1.png' width=\"750px\"/>\n",
    "</div>\n",
    "Image Description: A simple tensorflow graph with a single node\n",
    "\n",
    "Image source: University of Waterloo\n",
    "\n",
    "Thus, **a *graph's structure* is comprised of nodes and edges which together determine the composition and flow of the operations.** However, it is worth noting that computation graphs **do not** describe **how** nodes and edges should be used **(i.e. the graphs contain *steps* and not *results*).** This is reserved for another TensorFlow abstraction known as a **session** which will be discussed later.\n",
    "\n",
    "Another thing to note is that the computation graph **does not** live within your Python variables; it actually lives in the **global namespace** (i.e. the same block of memory as the global variables). How this works is that when you assign a TensorFlow object to a variable in Python, the variable becomes a pointer to the TensorFlow object in global memory. That is, the variable holds the address (or *location*) of where the object is stored in global memory. This becomes more apparent once we start working with more complicated models and distributed computing systems, so don't worry about this for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YiVIa3hrfERX"
   },
   "source": [
    "## Creating a basic graph\n",
    "With most of the technical background out of the way, we can go ahead and create our first graph. For the time being, we will use nodes of type `tf.constant` which act as *static values* in a graph (as the name suggests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ek7aA9RSfERX",
    "outputId": "2ee22bb7-6e3f-4257-acac-d9097c83f4c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# We would first import TensorFlow like any other Python library\n",
    "# Importing TensorFlow will create an empty default graph\n",
    "import tensorflow as tf\n",
    "\n",
    "# This is used to clear the default graph\n",
    "#tf.reset_default_graph()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "# Add some nodes to the default graph\n",
    "# Can add the node to the default graph by simply creating it\n",
    "tf.constant(2)\n",
    "\n",
    "# Or can add nodes to default graph by assigning them to variables\n",
    "two_node = tf.constant(2)\n",
    "two_node = tf.constant(2)\n",
    "three_node = tf.constant(3)\n",
    "four_node = tf.constant(4)\n",
    "\n",
    "# Print a few of the nodes to see the output\n",
    "print(two_node)\n",
    "print(three_node)\n",
    "print(four_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4WFVxrIfERc"
   },
   "source": [
    "Sending any of the variables to standard output (i.e., printing them) shows that it does return a `tf.Tensor` object, which is basically a *pointer* to the graph node that we created. Further details associated with the node are also included (i.e. *name*, *shape*, and *dtype*). We can visualize the simple graph we just created as follows:\n",
    "\n",
    "<div style=\"text-align:center;margin:15px;\">\n",
    "<img src='Module 9 images/vdiagram2.png' width=\"750px\"/>\n",
    "</div>\n",
    "Image Description: A simple tensorflow graph with 5 nodes\n",
    "\n",
    "Image source: University of Waterloo\n",
    "\n",
    "You may have noticed that before adding any of the nodes to the graph, we first cleared the *default graph* using the command `tf.reset_default_graph()`. This is good practice because **any node that is created will automatically be added to the default graph** (which is why it doesn't matter if we assign the node to a variable or if we just create it). Hence we would often need to reset our graph when me make changes to values, the architecture of our model, or if we just want to rerun everything from the beginning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VdHJdXwyfERc"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Tensor.graph is meaningless when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-de9d52ed596b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Access the graph that two_node belongs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mdefault_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtwo_node\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgraph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# Check if two_nodes's associated graph matches the default graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m#print(default_graph == tf.get_default_graph())\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36mgraph\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1226\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0mgraph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1227\u001B[0m     raise AttributeError(\n\u001B[1;32m-> 1228\u001B[1;33m         \"Tensor.graph is meaningless when eager execution is enabled.\")\n\u001B[0m\u001B[0;32m   1229\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1230\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: Tensor.graph is meaningless when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "# Access the graph that two_node belongs to\n",
    "default_graph = two_node.graph\n",
    "\n",
    "# Check if two_nodes's associated graph matches the default graph\n",
    "#print(default_graph == tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G5vn6OfGfERg"
   },
   "source": [
    "For most cases, working with the default graph will be sufficient. However, there may be times when you would want to work with multiple graphs simultaneously. This can be achieved by first creating the new graph(s) and then *temporarily* assigning them as the default graph, as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_9s_3refERg",
    "outputId": "f9efad9f-2d33-4564-8f87-d6d0840567c4"
   },
   "outputs": [],
   "source": [
    "# Create a new graph\n",
    "new_graph = tf.Graph()\n",
    "\n",
    "# Set new graph to default in a `with` statement\n",
    "with new_graph.as_default():\n",
    "    new_graph_node = tf.constant(2)\n",
    "    new_graph_node = tf.constant(2)\n",
    "# Any node added outside of this will be added back to the original\n",
    "# default graph and not the new one you just created\n",
    "\n",
    "# Check and compare our new graph with the default graph\n",
    "#print(new_graph_node.graph == tf.get_default_graph()) # This should prinit False\n",
    "\n",
    "# Check and compare the original graph with the default graph\n",
    "#print(two_node.graph == tf.get_default_graph()) # This should prinit True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xxkgc-jnfERj"
   },
   "source": [
    "As mentioned above, **every time we create a new `tf.constant` node, it is automatically created and added to the graph.** This holds even if the node we just created is functionally identical to one that already exists in the graph. It doesn't matter if we assign the node to a variable, if we reassign it to another variable, or not assign it at all! **In general, whenever you create a TensorFlow object, it is automatically placed on the default graph.**\n",
    "\n",
    "We can also access nodes (formerly dubbed as **operations**) that exist in our graph by using the `<graph>.get_operations()` method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R7REQVH_fERj",
    "outputId": "7d85f822-c41f-477b-d85d-77827aa3a920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Graph: <tensorflow.python.framework.ops.Graph object at 0x00000161EE856AC8> \n",
      "\n",
      "Operations: [] \n",
      "\n",
      "Operation Names: []\n"
     ]
    }
   ],
   "source": [
    "# First need to access the default graph\n",
    "#graph = tf.get_default_graph()\n",
    "graph = tf.compat.v1.get_default_graph()\n",
    "print(\"Default Graph:\", graph, '\\n')\n",
    "\n",
    "# To access the nodes (or operations) that are in the graph\n",
    "ops = graph.get_operations()\n",
    "print(\"Operations:\", ops,'\\n')\n",
    "\n",
    "# Print the names of the operations that are in the graph\n",
    "op_names = [op.name for op in ops]\n",
    "print(\"Operation Names:\", op_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "74t2kOKrfERm"
   },
   "source": [
    "Notice how each operation is named as `Const_n` where $n$ is used as a *counting suffix* to differentiate between other nodes of the same base name (`Const`, which is the default name for a `tf.constant` operation). That is, `Const_n` is the $(n+1)$-th node with the name `Const`. If we do not explicitly provide a **unique** name for an operation (this can be done using the `name` argument when creating the node), by default it will be assigned the names that you see above. This will be revisited later on in the module.\n",
    "\n",
    "To illustrate this idea, consider the code example below where we create five new nodes, where four will have a distinct name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1gEBdlNOfERm",
    "outputId": "fa7bf388-f3d7-4155-a0f3-2146c76295db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want a new graph, so we will clear the default one\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "# Will create four uniquely named nodes\n",
    "tf.constant(1, name='our_first_node')\n",
    "tf.constant(1, name='our_second_node')\n",
    "tf.constant(1, name='our_third_node')\n",
    "tf.constant(1, name='our_fourth_node')\n",
    "\n",
    "# The fifth node will have the same name as the fourth one\n",
    "tf.constant(1, name='our_fourth_node')\n",
    "\n",
    "# Now print the names of the nodes in the graph\n",
    "ops = tf.compat.v1.get_default_graph().get_operations()\n",
    "[op.name for op in ops]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UNtDbaj2fERp"
   },
   "source": [
    "As we stated above, we see that the first four nodes have the unique names that we provided. However, for the fifth node, we see the associated `_1` as expected. TensorFlow recognized that a node with the same name already exists in the graph and there is no suffix attached, so it automatically adds the `_1` before adding the new node. **This is to maintain the property that every node has a unique name in the computation graph.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BorzVjMGfERp"
   },
   "source": [
    "## Basic mathematical operations\n",
    "\n",
    "With most of the nuances out of the way, we will proceed by implementing some more complexity to the graph. Here, we will be adding some mathematical operations along with additional constant nodes to our graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fp0siDMofERp",
    "outputId": "ac5a7cf9-fa04-4174-df02-737d2289f17b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(30, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Clear the graph\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "# Create some new constant nodes\n",
    "two_node1 = tf.constant(2)\n",
    "two_node2 = tf.constant(3)\n",
    "three_node1 = tf.constant(3)\n",
    "three_node2 = tf.constant(3)\n",
    "\n",
    "# Now we will be adding two nodes together\n",
    "sum_twos = tf.add(two_node1, two_node2)\n",
    "sum_threes = tf.add(three_node1, three_node2)\n",
    "\n",
    "# To finish the graph, we will be multiplying the two sums together\n",
    "final_product = tf.multiply(sum_twos, sum_threes, name='Mul')\n",
    "print(final_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "koJTrtZqfERt",
    "outputId": "d22a2e35-ca93-43da-9082-d1a606908ed5"
   },
   "outputs": [],
   "source": [
    "# We will also create a simply function in Python that iteratively\n",
    "# prints the names of all the nodes in the default graph\n",
    "def node_names(tabs=1):\n",
    "    \"\"\"Print node names of default graph\"\"\"\n",
    "    graph = tf.compat.v1.get_default_graph()\n",
    "    ops = graph.get_operations()\n",
    "    \n",
    "    for op in ops:\n",
    "        print(\"Name:\", op.name, \"\\t\"*tabs, \"Type:\", op.type)\n",
    "\n",
    "node_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Y7ksAtPfERx"
   },
   "source": [
    "Congratulations! We have officially implemented our first real computation graph. Here we used the built-in TensorFlow **addition and multiplication operations**, however we could have also done `sum_twos = two_node1 + two_node2` which is equivalent to the corresponding TensorFlow operations. If you understand the code above, we effectively implemented the expression\n",
    "$$\n",
    "(2 + 2) \\times (3 + 3)\n",
    "$$\n",
    "as a computation graph. We can also visualize the graph as follows:\n",
    "\n",
    "<div style=\"text-align:center;margin:15px;\">\n",
    "<img src='images/vdiagram3.png' alt=\"drawing\" width=\"300\"/>\n",
    "</div>\n",
    "\n",
    "Image Description: A graph with nodes performing basic mathematical operations\n",
    "\n",
    "Image source: University of Waterloo\n",
    "\n",
    "\n",
    "You may have noticed that when we printed out the final product variable (i.e. the pointer to the `Mul` node in our graph) that the output was the `tf.Tensor` object and not the product of the prior two nodes. This is because, as noted above, **computation graphs contain only the *steps* of the computation and not the results**. In order to actual *run* the data flow in our graph to produce the desired outputs, we will need another abstraction available in TensorFlow known as a **Session**. We will discuss Sessions next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wZrAPRrfERx",
    "toc-hr-collapsed": false
   },
   "source": [
    "## Exercise\n",
    "\n",
    "For each of the following expressions, create an appropriate computation graph that maps the evaluation. **Do not simplify** the expressions before creating the graph. The graph should be a one-to-one representation.\n",
    "\n",
    "**Graph 1:**  \n",
    "$(2 + 3) \\times (5 - 2)$\n",
    "\n",
    "**Graph 2:** \n",
    "\n",
    "$\\dfrac{3}{4} - \\dfrac{2}{5} \\left( \\dfrac{5}{7} \\right)$\n",
    "\n",
    "**Hint:** Refer to the [**TensorFlow Python API**](https://www.tensorflow.org/api_docs/python/) for details on additional mathematical operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ou66UOYIfERx"
   },
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7qNiAI0pfERz"
   },
   "outputs": [],
   "source": [
    "# Graph 1\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UECdTI-qfER1"
   },
   "outputs": [],
   "source": [
    "# Graph 2\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KvlHoSSfER3"
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erloq3eafER3",
    "outputId": "94fdbdf7-442a-4ffc-b54f-2cef08f85bb3"
   },
   "outputs": [],
   "source": [
    "# Graph 1\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "# Create some new constant nodes\n",
    "a=tf.constant(2)\n",
    "b=tf.constant(3)\n",
    "c=tf.constant(5)\n",
    "\n",
    "# Now we will be adding two nodes together\n",
    "add = tf.add(a, b)\n",
    "sub = tf.subtract(c, a)\n",
    "mult = tf.multiply(add, sub)\n",
    "\n",
    "node_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u_4BLR4DfER7",
    "outputId": "467ec147-9aaf-4afc-9178-fbc6952a9345"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'reset_default_graph'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-22-ea44c1b31170>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Graph 2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreset_default_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconstant\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconstant\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
     ]
    }
   ],
   "source": [
    "# Graph 2\n",
    "tf.reset_default_graph()\n",
    "\n",
    "a=tf.constant(3)\n",
    "b=tf.constant(4)\n",
    "c=tf.constant(2)\n",
    "d=tf.constant(5) # Note, it is ok to reuse constant nodes! \n",
    "e=tf.constant(7)\n",
    "\n",
    "first = tf.divide(a, b)\n",
    "second = tf.divide(c, d)\n",
    "third = tf.divide(d, e)\n",
    "\n",
    "mult = tf.multiply(second, third)\n",
    "sub = tf.subtract(first,mult)\n",
    "\n",
    "\n",
    "node_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kGwXbNd5fER9"
   },
   "source": [
    "# Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k89_ORUAfER-"
   },
   "source": [
    "Recall that once a computational graph is constructed, a **Session** abstraction is then required in order to evaluate the associated calculations. More formally, **the role of a Session is to deal with all memory allocation and optimization required in order for TensorFlow to perform the calculations specified by a graph.** Hence, you can think of the computation graph as a *template* holding the desired calculations and describing the data flow. On the other hand, **a session will traverse through the template node-by-node to allocate the corresponding segments of memory for storing computational outputs.** Therefore, **any** computation performed within TensorFlow will require ***both*** a *graph* and a *session*.\n",
    "\n",
    "The session object in TensorFlow is denoted as `tf.Session`. Once a `tf.Session()` instance is created, you can use `<Session>.run(node)` to return the value of a node; TensorFlow will execute all the computations necessary to determine the value. Note that a session holds a *pointer* to the default graph, which in turn is constantly being updated with pointers to all the affiliated nodes. Hence it does not matter whether the session is created before or after the graph is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5rPBzqGfER-",
    "outputId": "09e7681a-1e33-49c5-c849-93ea0dea61c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# Clear the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create the graph\n",
    "\n",
    "two_node1 = tf.constant(2)\n",
    "two_node2 = tf.constant(3)\n",
    "three_node1 = tf.constant(3)\n",
    "three_node2 = tf.constant(3)\n",
    "sum_twos = tf.add(two_node1, two_node2)\n",
    "sum_threes = tf.add(three_node1, three_node2)\n",
    "final_product = tf.multiply(sum_twos, sum_threes, name='Mul')\n",
    "\n",
    "# Initialize the session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Use the session to calculate the final_node\n",
    "print(sess.run(final_product))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "khCJUV_ZfESC"
   },
   "source": [
    "We can also pass a *Python list* into `<Session>.run()` to evaluate multiple nodes and in turn, have it return multiple values. It is highly recommended that your code minimizes the amount of `<Session>.run()` calls invoked, as each time a `session.run` is called TensforFlow will recalculate all variables (whether or not they have been calculated in a previous run). Whenever possible, pass a list of multiple items in a single call rather than invoking multiple calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-YxgJtjLfESC",
    "outputId": "ab91d6ea-b1c9-43ff-eab1-f67ed3cdabf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 30]\n"
     ]
    }
   ],
   "source": [
    "# Example of passing multiple intermediate nodes\n",
    "print(sess.run([sum_twos, sum_threes, final_product]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "va9ax01ofESE"
   },
   "source": [
    "You can also utilize a `with` block as an alternative way of running a session. The session associated to the block will be set as the default session at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Te7X1FvfESF",
    "outputId": "2aecf8b9-2d4b-4f69-dd66-7dfc25ea7adc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# equivalent execution behaviour as the code example before when passing\n",
    "# multiple values\n",
    "with tf.Session() as sess:\n",
    "    for tensor in [sum_twos, sum_threes, final_product]:\n",
    "        print(tensor.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kb9-2HWEfESI"
   },
   "source": [
    "Note that calling `x.eval()` inside of the `with` block is the same as calling `<Session>.run(x)` outside of it. Using this convention enhances the readibility of your code. Furthermore, the session is automatically ended at the end of the block (i.e. any logic associated to the session is grouped). However, often times it may prove more convenient to make explicit calls to `<Session>.run()` instead (especially when dealing with multiple graphs and sessions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0zQBZY7gfESI"
   },
   "source": [
    "It is very important to note that **intermediate values that are computed by sessions *do not persist* between runs.** That is, all node values (with the exception of *variables*, which will be covered later) are dropped between graph evaluations. To illustrate this, consider the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O3OYiP9RfESI",
    "outputId": "5cbe8704-5b78-4be2-ab20-1de44f394e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# construct a simple computation graph\n",
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run first evalution\n",
    "    print(y.eval())\n",
    "    # Run second evalution\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kH3hNaBzfESM"
   },
   "source": [
    "To briefly describe the code segment above, we first define a basic graph and run two separate sessions to evaluate two nodes $y$ and $z$. On evaluation, TensorFlow will notice that $y$ is dependent on another node $x$, which in turn depends on another node $w$. So the dataflow will start with an evaluation of $w$, then $x$ and finally $y$. The final value $y$ is returned to the caller. A similar dataflow intuition can be applied to the valuation of $z$ in the following line.\n",
    "\n",
    "Even though both $y$ and $z$ are dependent on $w$ and $x$, TensorFlow will not *reuse* the calculated values of $w$ and $x$ from the preceding evaluation to compute $z$. This is because we made ***two separate*** calls to evaluate the same graph. Each call will essentially start a graph traversal from the beginning. **This is obviously not an efficient approach, especially when dealing with graphs with larger and more convoluted connections.**\n",
    "\n",
    "An efficient direction to compute $y$ and $z$ would be to evaluate both of the nodes within a ***single*** session run. This ensures that values used to calculate $y$ are still in memory and thus can be reused to calculate $z$. The following code segment demonstrates this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "34h-SBlgfESM",
    "outputId": "50145eb1-03b3-474c-9d62-82b9ebbef753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # evaluate both nodes within a single traversal\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FhsJZyHNfESP"
   },
   "source": [
    "# Placeholders and Input Dictionaries\n",
    "\n",
    "The graphs we have constructed thus far have been extremely simple (and are frankly not that useful!). There was no opportunity to pass an input that can alter a computation, for example. As a result the outputs of our graphs were **deterministic** (i.e. we could have just done the calculations on a calculator). To increase the complexity, suppose we wished to develop an application that constructed a computation graph that:\n",
    "- takes in some input\n",
    "- processes it in a consistent manner\n",
    "- returns the final output based on the initial input\n",
    "\n",
    "This can be achieved by using **placeholders**. A **placeholder** is simply a node that is designed to accept external input. Since no value is associated to the graph on creation, the realized value(s) are passed as an additional argument (specifically, `feed_dict`) in `<Session>.run()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KiQbPtY6fESP",
    "outputId": "2a343e23-357a-4277-cd4c-b166f47007cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Placeholder \t\t Type: Placeholder\n",
      "Name: Placeholder_1 \t\t Type: Placeholder\n",
      "Name: Mul \t\t Type: Mul\n",
      "Name: Const \t\t Type: Const\n",
      "Name: truediv \t\t Type: RealDiv\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Create a new graph consisting of two placeholders\n",
    "# The datatype of the placeholder must be specified\n",
    "ph1 = tf.placeholder(dtype=tf.float32)\n",
    "ph2 = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Multiply the inputs\n",
    "mul = tf.multiply(ph1, ph2)\n",
    "\n",
    "# Create a constant term\n",
    "const = tf.constant(2.0)\n",
    "\n",
    "# Divide the product by the new constant\n",
    "output = tf.divide(mul, const)\n",
    "\n",
    "# Call our custom function to verify the nodes\n",
    "node_names(tabs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eN6npJQQfESS"
   },
   "source": [
    "Our new graph can easily be visualized as follows:\n",
    "\n",
    "<div style=\"text-align:center;margin:15px;\">\n",
    "<img src='./images/vdiagram4.png' width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "Image Description: A graph with nodes performing basic multiplication and division operations\n",
    "\n",
    "Image source: University of Waterloo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fucKRY89fEST"
   },
   "source": [
    "The input to `feed_dict` must be in the form of a Python *dictionary*. Below is an example of passing an input dictionary through a session run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dp7uWh7KfEST",
    "outputId": "dd0a055e-595d-440c-cc66-241da04ad9bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create your input data and store as a dictionary\n",
    "inputs = {ph1 : 2.0, ph2 : 3.0}\n",
    "\n",
    "# Create a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Run output in sess.run, feed inputs dict\n",
    "sess.run(output, feed_dict=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4XMA79pIfESV"
   },
   "source": [
    "Here are some additional details about creating an input dictionary:\n",
    "- The **keys** of the `feed_dict` dictionary should be the variable names of the placeholder nodes from the graph. This is because the variables `ph1` and `ph2` hold pointers to the corresponding placeholder nodes created earlier. These pointers are what direct TensorFlow to where to place the specified values.\n",
    "- The **values** of the `feed_dict` dictionary are the data elements you wish to assign to each placeholder. These are typically scalar values or `numpy` arrays.\n",
    "As one may deduce, attempting to call `<Session>.run()` on a node that depends on a placeholder **without** providing the desired input will result in an error thrown by TensorFlow.\n",
    "\n",
    "Recall that TensorFlow will traverse through the graph computing all nodes that the specified node depends on (i.e. it will only compute values that are required, not all values in the graph). This is a major selling point for the TensorFlow framework. For large graphs, the run time is significantly reduced (especially if majority of the nodes are irrelevant to the current computation). Furthermore, this allows us to design large *multi-purpose* graphs that utilize a single shared set of nodes to do different things depending on the *computational path* taken. Hence, it may be helpful to think of a `<Session>.run()` call with respect to the computational path.\n",
    "\n",
    "The following code segment showcases how one can utilize `numpy` arrays as inputs for placeholders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HUFl7_kGfESW",
    "outputId": "46d88f2d-cf63-4a48-9110-96a4e36ef983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1: [12.   18.   15.75 20.25 13.5 ]\n",
      "Output 2: [ 6.     9.     7.875 10.125  6.75 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create the input arrays\n",
    "# Multiplying ints with floats will automatically cast\n",
    "# them as floats\n",
    "a = np.random.randint(5, 10, 5) * 0.5\n",
    "b = np.random.randint(5, 10, 5) * 0.5\n",
    "\n",
    "# Store the arrays as an input dictionary\n",
    "inputs = {ph1 : a, ph2 : b}\n",
    "\n",
    "# Create a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Run mul in sess.run, and feed the inputs dictionary\n",
    "print(\"Output 1:\", sess.run(mul, feed_dict=inputs))\n",
    "\n",
    "# Run output in sess.run, feed inputs dict\n",
    "print(\"Output 2:\", sess.run(output, feed_dict=inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sEQECZMpfESX"
   },
   "source": [
    "For clarification, we output the `mul` node to see how the data looks before the final division operation. This is required since we are randomly generating our input. Note that division does work as intended, and it is evaluated on an element basis (i.e., each element in the `mul` array is divided by `2.0`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1jDpByuUfESX",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Variables and Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aDq4bXfEfESY"
   },
   "source": [
    "At this point, we have been exposed to only two types of nodes:\n",
    "- `tf.constant`: a node with a fixed value  (i.e. has the same value for each run)\n",
    "- `tf.placeholder`: the value differs based on what is passed through by the user\n",
    "\n",
    "We refer to both of these types as **no-ancestor** nodes as they do not require (or depend on) other nodes to obtain their value. There is also a third type of node that one should consider. This node is unique as it *persists* (i.e. retains its' values) between session runs but can also be updated upon new runs. These nodes are deemed as **variables** and prove to be crucial to the whole practice of deep learning within TensorFlow.\n",
    "\n",
    "To develop a quick intuition of the use of variables, consider an iterative operation such as Gradient Descent. When one first builds a machine learning model in TensorFlow, the parameters (also called *weights* or *coefficients*) are generally stored as `tf.Variable` nodes. These nodes are updated at each training step, and retain their values between runs. During evaluation when we want our weight parameters to be fixed, we have the option to freeze the weight nodes so that we can make consistent predictions without a trained model. More often than not, all trainable parameters in your model will be implemented as `tf.variables`.\n",
    "\n",
    "There are two ways to create a variable in TensorFlow:\n",
    "- `tf.get_variable(name, shape)` <br/>\n",
    "    Takes two arguments `name` and `shape`. `name` is a string that will be used as the unique identifier relative to the global graph. `shape` is a list of integers associated to the tensor or node. Each integer in the array corresponds to the size of a dimension. For example, a $5\\times 10$ matrix will have `shape=[5,10]`. For scalars, use the empty list (i.e. `shape=[]`).\n",
    "    \n",
    "- `tf.Variable()` <br/>\n",
    "    Creates a new variable and is added to the global graph every time it is called. All of the default node behaviour mentioned above (i.e. naming convention for duplicates) applies to `tf.Variable` as well.\n",
    "\n",
    "We will revisit both of these methods in a later section with more detail. In this course, it is preferred to use the former way of creating variables (`tf.get_variable()`) as it enforces the user to explicitly define names which is an excellent habit to develop when building models in TensorFlow. Applying this convention will help you track the names of your variables, which is essential when your models get increasingly complex.\n",
    "\n",
    "Using variables, we can now create a new graph that simulates an output from a simple linear regression instance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "baF9I0NMfESZ",
    "outputId": "36e88e1b-8158-4d80-eb7f-e603f6eb9753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Placeholder \t\t Type: Placeholder\n",
      "Name: weights/Initializer/random_uniform/shape \t\t Type: Const\n",
      "Name: weights/Initializer/random_uniform/min \t\t Type: Const\n",
      "Name: weights/Initializer/random_uniform/max \t\t Type: Const\n",
      "Name: weights/Initializer/random_uniform/RandomUniform \t\t Type: RandomUniform\n",
      "Name: weights/Initializer/random_uniform/sub \t\t Type: Sub\n",
      "Name: weights/Initializer/random_uniform/mul \t\t Type: Mul\n",
      "Name: weights/Initializer/random_uniform \t\t Type: Add\n",
      "Name: weights \t\t Type: VariableV2\n",
      "Name: weights/Assign \t\t Type: Assign\n",
      "Name: weights/read \t\t Type: Identity\n",
      "Name: bias/Initializer/random_uniform/shape \t\t Type: Const\n",
      "Name: bias/Initializer/random_uniform/min \t\t Type: Const\n",
      "Name: bias/Initializer/random_uniform/max \t\t Type: Const\n",
      "Name: bias/Initializer/random_uniform/RandomUniform \t\t Type: RandomUniform\n",
      "Name: bias/Initializer/random_uniform/sub \t\t Type: Sub\n",
      "Name: bias/Initializer/random_uniform/mul \t\t Type: Mul\n",
      "Name: bias/Initializer/random_uniform \t\t Type: Add\n",
      "Name: bias \t\t Type: VariableV2\n",
      "Name: bias/Assign \t\t Type: Assign\n",
      "Name: bias/read \t\t Type: Identity\n",
      "Name: MatMul \t\t Type: MatMul\n",
      "Name: Add \t\t Type: Add\n"
     ]
    }
   ],
   "source": [
    "# Reset default graph \n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Create a placeholder for our X values (i.e. data points)\n",
    "# Recall that you must also include the data type as an argument\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "# Initialize model parameterss as variables (Weights and Bias)\n",
    "W = tf.get_variable('weights', [5,1], tf.float32)\n",
    "# Initialize bias as scalar\n",
    "b = tf.get_variable('bias', [], tf.float32)\n",
    "\n",
    "# Perform Matrix multiplication (X*W)\n",
    "mul = tf.matmul(X, W) \n",
    "\n",
    "# Add bias term\n",
    "Y = tf.add(mul, b)\n",
    "\n",
    "node_names(tabs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c5-ZDd1afESb"
   },
   "source": [
    "## Variable Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBJiubabfESb"
   },
   "source": [
    "If you attempt to decipher the output, you may notice that each of the variable nodes is actually associated to multiple TensorFlow operations. This is because **when a variable is first created, only the appropriate memory is allocated; no value is actually assigned to it (i.e. default value will be `null`)**. To accommodate for this, TensorFlow randomly assigns values to variables based on a specified generation method. This is formerly denoted as **variable initialization** (i.e. assigning values to variables). In general, **initialization involves multiple steps** (depending on how values are generated) **which are what we see in the output above.** These steps are broken into multiple operations for the graph.\n",
    "\n",
    "TensorFlow defaults to the `tf.initializers.random_uniform` initializer (i.e. value generator) if none is specified. However, there are a large number of additional initializers that can be used instead, all available through the `tf.initializers` module. Some include:\n",
    "- `zeros`: Generates tensors initialized to zero.\n",
    "- `ones`: Generates tensors initialized to one.\n",
    "- `random_normal`: Generates tensors with respect to a normal distribution.\n",
    "- `identity`: Generates the identity matrix.\n",
    "For additional initializers, refer to the official TensorFlow documentation [Module tf.initializers](https://www.tensorflow.org/api_docs/python/tf/initializers).\n",
    "\n",
    "We will reproduce the graph above, this time initializing the variables to a value of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0houS6OtfESb",
    "outputId": "6325ef7a-b53a-4515-f9ef-9450bfeb46c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Placeholder \t\t Type: Placeholder\n",
      "Name: weights/Initializer/ones \t\t Type: Const\n",
      "Name: weights \t\t Type: VariableV2\n",
      "Name: weights/Assign \t\t Type: Assign\n",
      "Name: weights/read \t\t Type: Identity\n",
      "Name: bias/Initializer/ones \t\t Type: Const\n",
      "Name: bias \t\t Type: VariableV2\n",
      "Name: bias/Assign \t\t Type: Assign\n",
      "Name: bias/read \t\t Type: Identity\n",
      "Name: MatMul \t\t Type: MatMul\n",
      "Name: Add \t\t Type: Add\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "# Assign the new initializers to the variables\n",
    "W = tf.get_variable('weights', [5, 1], tf.float32, initializer = tf.initializers.ones)\n",
    "b = tf.get_variable('bias', [], tf.float32, initializer = tf.initializers.ones)\n",
    "\n",
    "# Perform Matrix multiplication (X*W)\n",
    "mul = tf.matmul(X, W) \n",
    "# Add bias term\n",
    "Y = tf.add(mul, b)\n",
    "\n",
    "node_names(tabs = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DN_fCxv8fESf"
   },
   "source": [
    "Note that there are significantly less operations associated to the variables. This is a result of the `ones` initializer being quite a bit less cumbersome. It requires fewer operations than the default `random_uniform` initializer as TensorFlow simply needs to assign the value $1$ to the variable without having to generate anything from a distribution.\n",
    "\n",
    "At this point, we have a graph with our variables initialized. However, we are unable to start a session. This is because **initializers must be run *separately* beforehand**. The `get_variable` method simply establishes the connection between nodes in the graph (i.e. we defined what variables will be associated to what initializer). **Thus, one must now explicitly inform the session to make an update.**\n",
    "\n",
    "This can easily be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DrJVo1GcfESg",
    "outputId": "1635e3af-22da-4de4-d1a3-a95346cae3d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# run the initializers first\n",
    "sess.run([W.initializer, b.initializer])\n",
    "# now run the desired node with the corresponding input\n",
    "sess.run(Y, feed_dict = {X : np.array([[1,2,3,4,5]])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SZ3UjYIkfESj"
   },
   "source": [
    "If there are many variables in the graph, **you can also simply initialize them all at once using `tf.global_variables_initializer()`.** On creation, this function will look at the global graph and automatically add dependencies to every instance of `tf.initializer`. Hence, when we evaluate the graph with the session, it will run the individual initializers which in turn allows us to run the node's session without any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9JYyajaNfESj",
    "outputId": "78b73269-25c1-41cd-8875-8731cee74855"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# run all of the initializers in the global graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# now run the desired node with the corresponding input\n",
    "sess.run(Y, feed_dict= {X:np.array([[1,2,3,4,5]])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qrYYMWAOfESo"
   },
   "source": [
    "Again, it is important to explicitly run an initializer in order to evaluate any nodes that depend on the associated `tf.variable` nodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "REwVzdpHfESo"
   },
   "source": [
    "## Variable Assignment\n",
    "\n",
    "As an alternative to variable initialization, one can also directly assign desired values to variables using `tf.assign()`. The method signature includes two required parameters:\n",
    "- `ref`: The target variable to which you will be assigning the value(s) to\n",
    "- `value`: The value(s) being assigned to the variables\n",
    "\n",
    "To demonstrate the use, we will reconstruct the previous graph using assignment nodes. It is worth noting from the code that we are assigning `tf.constant` nodes to the variables as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmW-tGWrfESp",
    "outputId": "0b0010ac-ea80-43d6-acfe-118adadb3478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Placeholder \t\t Type: Placeholder\n",
      "Name: weights/Initializer/random_uniform/shape \t\t Type: Const\n",
      "Name: weights/Initializer/random_uniform/min \t\t Type: Const\n",
      "Name: weights/Initializer/random_uniform/max \t\t Type: Const\n",
      "Name: weights/Initializer/random_uniform/RandomUniform \t\t Type: RandomUniform\n",
      "Name: weights/Initializer/random_uniform/sub \t\t Type: Sub\n",
      "Name: weights/Initializer/random_uniform/mul \t\t Type: Mul\n",
      "Name: weights/Initializer/random_uniform \t\t Type: Add\n",
      "Name: weights \t\t Type: VariableV2\n",
      "Name: weights/Assign \t\t Type: Assign\n",
      "Name: weights/read \t\t Type: Identity\n",
      "Name: bias/Initializer/random_uniform/shape \t\t Type: Const\n",
      "Name: bias/Initializer/random_uniform/min \t\t Type: Const\n",
      "Name: bias/Initializer/random_uniform/max \t\t Type: Const\n",
      "Name: bias/Initializer/random_uniform/RandomUniform \t\t Type: RandomUniform\n",
      "Name: bias/Initializer/random_uniform/sub \t\t Type: Sub\n",
      "Name: bias/Initializer/random_uniform/mul \t\t Type: Mul\n",
      "Name: bias/Initializer/random_uniform \t\t Type: Add\n",
      "Name: bias \t\t Type: VariableV2\n",
      "Name: bias/Assign \t\t Type: Assign\n",
      "Name: bias/read \t\t Type: Identity\n",
      "Name: Const \t\t Type: Const\n",
      "Name: Const_1 \t\t Type: Const\n",
      "Name: Assign \t\t Type: Assign\n",
      "Name: Assign_1 \t\t Type: Assign\n",
      "Name: MatMul \t\t Type: MatMul\n",
      "Name: Add \t\t Type: Add\n"
     ]
    }
   ],
   "source": [
    "# Reset default graph \n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "\n",
    "W = tf.get_variable('weights', [5,1], tf.float32)\n",
    "b = tf.get_variable('bias', [], tf.float32)\n",
    "\n",
    "# First create constant nodes to be assigned to variables\n",
    "W_assign = tf.constant(np.array([[1.0], [1.0], [1.0], [1.0], [1.0]]), tf.float32)\n",
    "b_assign = tf.constant(1.0)\n",
    "\n",
    "# construct the assignment nodes with the designated values\n",
    "assign_node_W = tf.assign(W, W_assign)\n",
    "assign_node_b = tf.assign(b, b_assign)\n",
    "\n",
    "# Perform Matrix multiplication (X*W)\n",
    "mul = tf.matmul(X,W) \n",
    "\n",
    "# Add bias term\n",
    "Y = tf.add(mul, b)\n",
    "\n",
    "node_names(tabs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3y4JG6NLfESs"
   },
   "source": [
    "Now we have essentially assigned the constant term $1$ to all the variables in the graph. This is no different than what was being done with the `ones` initializer, but it provides some context on how to explicitly define the values being assigned to `tf.variable` nodes. Furthermore, we no longer need to run an initializer, however we **must** run the assignment nodes prior to running the other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PhfKyeHJfESs",
    "outputId": "c0210ad9-5c15-4314-fb8f-e8da67139626"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "# run the assignment nodes\n",
    "sess.run ([assign_node_W, assign_node_b])\n",
    "# run the final node\n",
    "sess.run(Y, feed_dict= {X:np.array([[1,2,3,4,5]])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gJQE1lPDfESv",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Run the graph of the simple linear model above 10 times, each time update the `W` and `b` variables by adding 1 to each value. For each run, input `np.array([[1,2,3,4,5]])` as your X input. Remember, you can use `tf.assign` to assign new values to the variables on each iteration of your loop (ie. `tf.assign(W, W+1)`), **but you must also run the tf.assign operation to make the updates.**\n",
    "\n",
    "Remember to print the value of Y after each loop iteration!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KRNrsH-fESv"
   },
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6d9ND60KfESx"
   },
   "outputs": [],
   "source": [
    "# Reset default graph \n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Set up graph\n",
    "X = tf.placeholder(tf.float32)\n",
    "W = tf.get_variable('weights', [5,1], tf.float32)\n",
    "b = tf.get_variable('bias', [], tf.float32)\n",
    "mul = tf.matmul(X,W) \n",
    "Y = tf.add(mul, b)\n",
    "\n",
    "# Initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Create Variable update loop \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    ### YOUR CODE HERE ###    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUa_3pX8fESy"
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LaKg5apQfESz",
    "outputId": "d956c92b-144b-40ff-d475-9d848e44e33c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.665714]]\n",
      "[[19.665714]]\n",
      "[[34.665714]]\n",
      "[[49.665714]]\n",
      "[[64.66571]]\n",
      "[[79.66571]]\n",
      "[[94.6657]]\n",
      "[[109.6657]]\n",
      "[[124.6657]]\n",
      "[[139.66571]]\n"
     ]
    }
   ],
   "source": [
    "# Reset default graph \n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Set up graph\n",
    "X = tf.placeholder(tf.float32)\n",
    "W = tf.get_variable('weights', [5,1], tf.float32)\n",
    "b = tf.get_variable('bias', [], tf.float32)\n",
    "mul = tf.matmul(X,W) \n",
    "Y = tf.add(mul, b)\n",
    "\n",
    "# Initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Create Variable update loop \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(10):\n",
    "        # Run the Y node\n",
    "        Y_output = sess.run(Y, feed_dict = {X : np.array([[1,2,3,4,5]])})       \n",
    "        print(Y_output)\n",
    "        # Run the variable update\n",
    "        sess.run(tf.assign(W, W+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5Ip9jrKfES1",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Names & Scopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i0jSMp4JfES1"
   },
   "source": [
    "Recall that on every instance of a variable creation, TensorFlow requires you to provide a unique name for the variable. In fact, every Tensor in the graph has a corresponding unique name even if it was not explicitly defined. These names can be accessed through the `.name` attribute for any tensor, operation or variable.\n",
    "\n",
    "Under most circumstances, the names will be generated for you. For `tf.constant` nodes, you may remember that TensorFlow will label those not explicitly named as `Const_n` where $n$ is the instance count of that particular node on the graph. Furthermore, if you provide a node with a name that already exists on the graph, TensorFlow will automatically append an additiona `_n` suffix for the more recent addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TL3fKnBmfES2",
    "outputId": "bf191e37-9964-4916-d446-500015fcea5f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Const',\n",
       " 'Const_1',\n",
       " 'Const_2',\n",
       " 'Placeholder',\n",
       " 'Placeholder_1',\n",
       " 'Placeholder_2',\n",
       " 'my_variable/initial_value',\n",
       " 'my_variable',\n",
       " 'my_variable/Assign',\n",
       " 'my_variable/read',\n",
       " 'my_variable_1/initial_value',\n",
       " 'my_variable_1',\n",
       " 'my_variable_1/Assign',\n",
       " 'my_variable_1/read',\n",
       " 'my_variable_2/initial_value',\n",
       " 'my_variable_2',\n",
       " 'my_variable_2/Assign',\n",
       " 'my_variable_2/read']"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Here we will create a bunch of miscellaneous nodes\n",
    "# and see how their names are defined\n",
    "iterations = 3\n",
    "\n",
    "for i in range(iterations):\n",
    "    tf.constant(i)\n",
    "\n",
    "for i in range(iterations):\n",
    "    tf.placeholder(dtype=tf.float32)\n",
    "    \n",
    "for i in range(iterations):\n",
    "    tf.Variable(i, name='my_variable')\n",
    "\n",
    "# Get names of all the nodes\n",
    "[op.name for op in tf.get_default_graph().get_operations()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3_r83UofES4"
   },
   "source": [
    "Because of TensorFlow's ability to automatically assign names and suffixes to each variable, it may seem like it removes the need for the developer to be concerned with that criteria. However, giving names with better context can prove beneficial when debugging. For graphs built with a large number of operations (i.e. a deep neural network), it may be difficult to sort through the different graph components. Furthermore, giving a name for every node will be unfeasible. Applying name **Scopes** alleviate much of this potential headache by providing the ability to *subdivide* your graph into *smaller segments*. These segments can then be grouped into different sections which in turn can be given a common over-arching name.\n",
    "\n",
    "To implement scopes, you would simply utilize the `with` statement to wrap a portion of your graph (i.e. `with tf.variable_scope(<scope_name>)`). **Doing so will add a prefix (which will be the scope name) to the names of all the nodes created within the code block.** Moreover, you are also able to embed (or nest) scopes within one another, allowing you to further subdivide and group your operations. **Each nested scope will be concatenated to the node name's existing scope via a forward slash.**\n",
    "\n",
    "Again, we will revisit the linear regression example to now implement various scopes to group the relations within our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTDfF-8YfES4",
    "outputId": "adbc8dcf-0d41-4ae5-c517-cbc2eb89b5da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: INPUTS/Placeholder \t\t Type: Placeholder\n",
      "Name: PARAMS/weights/Initializer/ones \t\t Type: Const\n",
      "Name: PARAMS/weights \t\t Type: VariableV2\n",
      "Name: PARAMS/weights/Assign \t\t Type: Assign\n",
      "Name: PARAMS/weights/read \t\t Type: Identity\n",
      "Name: PARAMS/bias/Initializer/ones \t\t Type: Const\n",
      "Name: PARAMS/bias \t\t Type: VariableV2\n",
      "Name: PARAMS/bias/Assign \t\t Type: Assign\n",
      "Name: PARAMS/bias/read \t\t Type: Identity\n",
      "Name: MATH_STEP1/prediction \t\t Type: MatMul\n",
      "Name: MATH_STEP1/MATH_STEP2/prediction \t\t Type: Add\n"
     ]
    }
   ],
   "source": [
    "# Reset default graph \n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope('INPUTS'):\n",
    "    X = tf.placeholder(tf.float32)\n",
    "\n",
    "# Initialize model params as variables (Weights and Bias)\n",
    "with tf.variable_scope('PARAMS'):\n",
    "    W = tf.get_variable('weights', [5,1], tf.float32, \n",
    "                        initializer = tf.initializers.ones)\n",
    "    b = tf.get_variable('bias', [], tf.float32, \n",
    "                        initializer = tf.initializers.ones)\n",
    "\n",
    "with tf.variable_scope('MATH_STEP1'):\n",
    "    mul = tf.matmul(X,W,name='prediction')\n",
    "    # an example of a nested scope here\n",
    "    with tf.variable_scope('MATH_STEP2'):\n",
    "        # Add bias term\n",
    "        Y = tf.add(mul, b, name='prediction')\n",
    "\n",
    "node_names(tabs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjZuXMfCfES9"
   },
   "source": [
    "As we can see, the graph looks to be more organized. **A final thing worth noting is how we were able to name two nodes as `prediction` in the final code block without TensorFlow appending a suffix. This is because the nodes associated with the name are in two different scopes (even if one is embedded within the other, they are still in different scopes) so we can uniquely identify them by their group.** One can draw an analogy between scopes with folder directories on your desktop. It is not possible to have two files with the same name in the same folder, however if they were in separate folders then we can have the same name for both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tH9YU9_ffES9",
    "toc-hr-collapsed": true
   },
   "source": [
    "# Saving & Loading Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RkIZU8TofES_"
   },
   "source": [
    "## Saving Graphs\n",
    "\n",
    "TensorFlow comes with the ability to save and load graphs through file systems. The loaded graphs can essentially be reused and modified as if they were originally developed on your machine in the first place. This functionality is extremely important for when we dive into working with pre-trained models. With neural networks it is often common practice to save trained weights and graph structure for reuse rather than retraining the entire model on every instance.\n",
    "\n",
    "TensorFlow's built-in `tf.train.Saver()` function allows the user to save both the graph and variables into a single `.model` file. Note that `tf.train.Saver` is not itself a graph node, but is a higher-level class with the intention of performing functions on top of pre-existing graphs.\n",
    "\n",
    "We will save the most recent iteration of our simple linear model (i.e. the one using the scopes in the previous section)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zaljpb1SfES_",
    "outputId": "b7a37172-a36c-49e7-e2ce-4f9f148178b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: INPUTS/X \t\t Type: Placeholder\n",
      "Name: PARAMS/W/Initializer/ones \t\t Type: Const\n",
      "Name: PARAMS/W \t\t Type: VariableV2\n",
      "Name: PARAMS/W/Assign \t\t Type: Assign\n",
      "Name: PARAMS/W/read \t\t Type: Identity\n",
      "Name: PARAMS/b/Initializer/ones \t\t Type: Const\n",
      "Name: PARAMS/b \t\t Type: VariableV2\n",
      "Name: PARAMS/b/Assign \t\t Type: Assign\n",
      "Name: PARAMS/b/read \t\t Type: Identity\n",
      "Name: MATH_1/prediction \t\t Type: MatMul\n",
      "Name: MATH_1/MATH_2/pred \t\t Type: Add\n",
      "Name: init \t\t Type: NoOp\n",
      "Name: save/Const \t\t Type: Const\n",
      "Name: save/SaveV2/tensor_names \t\t Type: Const\n",
      "Name: save/SaveV2/shape_and_slices \t\t Type: Const\n",
      "Name: save/SaveV2 \t\t Type: SaveV2\n",
      "Name: save/control_dependency \t\t Type: Identity\n",
      "Name: save/RestoreV2/tensor_names \t\t Type: Const\n",
      "Name: save/RestoreV2/shape_and_slices \t\t Type: Const\n",
      "Name: save/RestoreV2 \t\t Type: RestoreV2\n",
      "Name: save/Assign \t\t Type: Assign\n",
      "Name: save/Assign_1 \t\t Type: Assign\n",
      "Name: save/restore_all \t\t Type: NoOp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Reset default graph \n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope('INPUTS'):\n",
    "    X = tf.placeholder(name='X', dtype=tf.float32)\n",
    "\n",
    "# Initialize model params as variables (Weights and Bias)\n",
    "with tf.variable_scope('PARAMS'):\n",
    "    W = tf.get_variable('W', [5,1], tf.float32, \n",
    "                        initializer = tf.initializers.ones)\n",
    "    b = tf.get_variable('b', [], tf.float32, \n",
    "                        initializer = tf.initializers.ones)\n",
    "\n",
    "with tf.variable_scope('MATH_1'):\n",
    "    mul = tf.matmul(X,W,name='prediction')\n",
    "    # an example of a nested scope here\n",
    "    with tf.variable_scope('MATH_2'):\n",
    "        # Add bias term\n",
    "        Y = tf.add(mul, b, name='pred')\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "# we create an instance of the saver object here\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Set you model path below\n",
    "MODEL_PATH = '.\\\\models'\n",
    "MODEL_NAME = 'my_model.model'\n",
    "# we explicitly save the model here, after running the session\n",
    "saver.save(sess, os.path.join(MODEL_PATH, MODEL_NAME))\n",
    "node_names(tabs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SNdpNNcDfETD"
   },
   "source": [
    "Wherever you saved the model to (based on the `MODEL_PATH` variable above), there should now be four distinct files:\n",
    "\n",
    "    checkpoint\n",
    "    my_model.model.data-00000-of-00001\n",
    "    my_model.model.index\n",
    "    my_model.model.meta\n",
    "\n",
    "The first 'checkpoint' file is not crucial for reloading your model, however it does save important information about what stage (e.g. epoch) in training you reached. If you are training large neural network and want to periodically save the model, the checkpoint file will update at every save. If your training is interrupted at a certain point, you will know exactly where it left off. We will dig more into this in the next module when we begin to train deep neural nets.\n",
    "\n",
    "The last 3 files collectively store the information needed to recreate/reload your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0KCPz8AfETD"
   },
   "source": [
    "There’s a lot of stuff to break down here. Consider the following questions:\n",
    "\n",
    "1. **Why does it output four files, when we only saved one model?**\n",
    "\n",
    "    In short, the information needed to recreate the model is divided among them. **If you want to copy or back up a model, make sure you bring all three of the files (the three prefixed by your filename).** Here’s a quick description of each:\n",
    "\n",
    "    - **tftcp.model.data-00000-of-00001** contains the weights of your model. It’s most likely the largest file here.\n",
    "    - **tftcp.model.meta** is the network structure of your model. It contains all the information needed to re-create your graph.\n",
    "    - **tftcp.model.index** is an indexing structure linking the first two things. It says “where in the data file do I find the parameters corresponding to this node?”\n",
    "\n",
    "\n",
    "\n",
    "2. A second question you may have is, **why did I go through all the trouble of creating a `tf.Session` and `tf.global_variables_initializer` for this example?**\n",
    "\n",
    "Well, if we’re going to save a model, we need to have something to save. Recall that computations live in the graph, but values live in the session. The `tf.train.Saver` can access the structure of the network through a global pointer to the graph. But when we go to save the values of the variables (i.e. the weights of the network), we need to access a `tf.Session` to see what those values are; **that’s why `sess` is passed in as the first argument of the save function.** Additionally, attempting to save uninitialized variables will throw an error, because **attempting to access the value of an uninitialized variable always throws an error.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AS9JYFqLfETF",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Loading a Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1YtByn0fETF"
   },
   "source": [
    "Loading a model from the `model` file involves some preparation. Before loading the model, you will need to re-create all of the variables that you wish to access in the saved model. These variables should have identical names, shapes, and datatypes as what the model had when it was original saved. \n",
    "\n",
    "Here we will load a model from the file `my_model.model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMgfj1Z7fETG",
    "outputId": "009ba008-8ab2-4545-de0f-de243c55f28f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from .\\models\\my_model.model\n",
      "W: [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "b: 1.0\n",
      "Name: PARAMS/W/Initializer/ones \t\t Type: Const\n",
      "Name: PARAMS/W \t\t Type: VariableV2\n",
      "Name: PARAMS/W/Assign \t\t Type: Assign\n",
      "Name: PARAMS/W/read \t\t Type: Identity\n",
      "Name: PARAMS/b/Initializer/ones \t\t Type: Const\n",
      "Name: PARAMS/b \t\t Type: VariableV2\n",
      "Name: PARAMS/b/Assign \t\t Type: Assign\n",
      "Name: PARAMS/b/read \t\t Type: Identity\n",
      "Name: save/Const \t\t Type: Const\n",
      "Name: save/SaveV2/tensor_names \t\t Type: Const\n",
      "Name: save/SaveV2/shape_and_slices \t\t Type: Const\n",
      "Name: save/SaveV2 \t\t Type: SaveV2\n",
      "Name: save/control_dependency \t\t Type: Identity\n",
      "Name: save/RestoreV2/tensor_names \t\t Type: Const\n",
      "Name: save/RestoreV2/shape_and_slices \t\t Type: Const\n",
      "Name: save/RestoreV2 \t\t Type: RestoreV2\n",
      "Name: save/Assign \t\t Type: Assign\n",
      "Name: save/Assign_1 \t\t Type: Assign\n",
      "Name: save/restore_all \t\t Type: NoOp\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "# reconstruct the associated model variables we want to extract\n",
    "W = tf.get_variable('PARAMS/W', [5,1], tf.float32, initializer = tf.initializers.ones)\n",
    "b = tf.get_variable('PARAMS/b', [], tf.float32, initializer = tf.initializers.ones)\n",
    "\n",
    "# create the saver object\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # load the model from the corresponding file\n",
    "    saver.restore(sess, '.\\\\models\\\\my_model.model')\n",
    "    weights, bias = sess.run([W,b])\n",
    "\n",
    "print(\"W:\", weights)\n",
    "print(\"b:\", bias)\n",
    "node_names(tabs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qH2gmVqKfETH"
   },
   "source": [
    "Note that we were not required to initialize either $W$ or $b$ before running the model. This is because the `restore` operation moves the values from the model file into the session's variables. **Since the session no longer holds any null values** (i.e. the variables are no longer empty), **the initialization process becomes pointless.** In fact, it is often dangerous to run an initializer after loading a graph. Since the values being placed into the variables were calculated beforehand, running an initializer will override these loaded values and thus destroy all the work associated with deriving these values in the first place.\n",
    "\n",
    "When a `tf.train.Saver` object is initialized, it looks at the current state of the global graph and obtains a list of variables. This list is permanently stored for the `Saver` object to reference. One can consider this list as the variables that the `Saver` \"cares\" about. Using the `.varlist` property, we can make the following observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ow9zL1lYfETH",
    "outputId": "95838b35-3c46-4b1b-e0ef-7445a1399ce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'a:0' shape=() dtype=float32_ref>, <tf.Variable 'b:0' shape=() dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "# Reset default graph \n",
    "tf.reset_default_graph()\n",
    "\n",
    "# variables created before a saver is created\n",
    "a = tf.get_variable('a', [])\n",
    "b = tf.get_variable('b', [])\n",
    "# saver object\n",
    "saver = tf.train.Saver()\n",
    "# variables created after the saver is created\n",
    "c = tf.get_variable('c', [])\n",
    "# check out how the variable list looks like\n",
    "print(saver._var_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IS807yjFfETK"
   },
   "source": [
    "Interestingly enough, $c$ is not present in the variable list. This is because it wasn't on the global graph before the `saver` was created, hence it will not be in the list of variables that the `saver` collects on instantiation. Thus, it is a good idea to **ensure that all variables are created before making a `saver` object.**\n",
    "\n",
    "On the other hand, there are also circumstances present where one may actually want to only save a subset of the variables. If this is the case, you are able to pass the `var_list` explicitly when creating a `tf.train.Saver`. This allows one to specify the subset of available variables that you wish to keep track of.\n",
    "\n",
    "In the next section of this module, we will start to put all of the TensorFlow tools you have learned together to construct some simple models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVxz4fxNvRHS"
   },
   "source": [
    "**End of Part 1.**\n",
    "\n",
    "This notebook makes up one part of this module. Now that you have completed this part,\n",
    "please proceed to the next notebook in this module.\n",
    "If you have any questions, please reach out to your peers using the discussion boards. If you and your peers are unable to come to a suitable conclusion, do not hesitate to reach out to your instructor on the designated discussion board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "REwVzdpHfESo",
    "gJQE1lPDfESv",
    "0KRNrsH-fESv",
    "JUa_3pX8fESy"
   ],
   "name": "Module09_Part1_edited_by_ML_MC.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}