{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJzifVmw3ePP"
   },
   "source": [
    "<font size=\"6\"><b>Module 9 Part 2: Using TensorFlow</b></font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dl7j-21I3ePQ"
   },
   "source": [
    "In this part of the module, we will use the [**TensorFlow**](https://www.tensorflow.org/) library introduced in the previous section to start building and applying learning algorithms. We will go over the corresponding syntax and theory associated to model building in TensorFlow and specifically look at building, executing and visualizing said models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z90senxh3ePR"
   },
   "source": [
    "<font size=\"6\">Table of Contents</font>\n",
    "\n",
    "- 1 Model Construction\n",
    "    - 1.1 Manually Processing Gradients\n",
    "    - 1.2 Using `tf.autodiff`\n",
    "    - 1.3 Using `tf.train.optimizers`\n",
    "- 2 Model Execution\n",
    "    - 2.1 Batch Gradient Descent\n",
    "    - 2.2 Mini-Batch Gradient Descent\n",
    "    - 2.3 Saving & Restoring Models\n",
    "- 3 Visualizing models with TensorBoard\n",
    "    - 3.1 TensorBoard overview & tf.logging\n",
    "    - 3.2 Accessing TensorBoard\n",
    "    - 3.2 Improving your  TensorBoard output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ATY83JFw3ePS"
   },
   "source": [
    "# Model Development\n",
    "\n",
    "Compared to other machine learning libraries such as `Sci-Kit Learn`, TensorFlow involves quite a few more additional steps when building a model. However, these additional steps can be considered a tradeoff for more refined models (i.e. finer tuned parameters) and optimized performance. Before diving into the actual code, it is good to note that models in TensorFlow are generally split into two parts:\n",
    "\n",
    "1.  **Building a Computation Graph**\n",
    "\n",
    "    The first part involves creating the computation graph associated to the model scheme (refer to the previous section for more details on computation graphs and TensorFlow's architecture). Preparation in this stage includes configuring input variables, defining an appropriate loss function, and optimizing the model (i.e. `training_op`). Because of all the work involved, this stage is widely considered as the **construction phase**.\n",
    "\n",
    "2.  **Executing the Model**\n",
    "\n",
    "    This part involves iterating through the model created in the previous stage for $n$ number of epochs. After each epoch, your loss funciton may increase or decrease dependsing on the complexity of your model and whether or not you are using mini-batch training. That said, if your model is consturcted correctly and you have the right data, the loss should generally be decreasing over several epochs. You may also want to periodically store (or print) the loss values for your training and validation sets to ensure that your loss funciton is indeed decreasing. Finally, you may also wish to save the model at regular intervals, especially if you are training a model for hours (or days) on massive data sets.\n",
    "\n",
    "To help grasp the concepts introduced in this module, we will go about implementing some of the techniques manually (i.e. batch gradient descent) and then using the built-in functionality available in TensorFlow to provide a comparison.\n",
    "\n",
    "**The Dataset:**\n",
    "\n",
    "We will be working with the *MNIST* dataset available in the `sklearn.datasets` package to build our first model. For context, this data is associated with handwritten digits, but this should not be relevant to complete the remainder of this module. Specifically, we will be implementing a multiclass softmax regression model. However, it is worth noting that using TensorFlow for a model this simple would generally be considered excessive; the main reason being the dataset itself is small. Recall that a benefit of TensorFlow is its ability to easily distribute computations to allow for sufficient performance when dealing with convoluted models with large amounts of data. That said, this simple classification model is used to illustrate the workflow for developing, executing and making predictions with TensorFlow.\n",
    "\n",
    "Note that we will also normalize the input vectors (i.e. the data) before feeding it into our model. As you know from previous modules, it is very important to normalize (ie. standardize or scale) your data  prior to feeding it into a machine learning algorithm. This is particularily true for deep learning models, which we discuss in the next module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1247,
     "status": "ok",
     "timestamp": 1562795674028,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "gAOIDE2O3ePS",
    "outputId": "26a5f48c-42c7-47c8-c613-cef1864ec96e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (1437, 65)\n",
      "X_val: (360, 65)\n",
      "y_train: (1437,)\n",
      "y_val: (360,)\n"
     ]
    }
   ],
   "source": [
    "# Load the data and the scalar\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load the dataset\n",
    "mnist = datasets.load_digits()\n",
    "\n",
    "# Split into the explanatory and response variables\n",
    "X_mnist = mnist[\"data\"]\n",
    "y_mnist = mnist[\"target\"]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_mnist = scaler.fit_transform(X_mnist)\n",
    "\n",
    "# Add bias term as a new column in our X matrix\n",
    "X_mnist = np.c_[np.ones((X_mnist.shape[0],1)), X_mnist]\n",
    "\n",
    "# Train test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_mnist, y_mnist, test_size=0.2, shuffle=True)\n",
    "\n",
    "# Print shape of final dataset for sanity purposes\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K-vlcC1p3ePX"
   },
   "source": [
    "## Manually Processing Gradients\n",
    "\n",
    "As mentioned earlier, we will first manually derive the gradients and place the corresponding formulae into the global graph. In the code segment below, we will be running a multinomial logistic regression model (also known as **softmax regression**) using TensorFlow's built in matrix calculation functionalities. Below is a brief summary of the logic flow for our code.\n",
    "\n",
    "**Step 1: Set the values for hyperparameters**\n",
    "- We need to define some important hyperparameters including the learning rate, $m$ (i.e. the number of observations) and $n$ (i.e. the number of features).\n",
    "    \n",
    "**Step 2: Add placeholder nodes for input**\n",
    "\n",
    "- Next we need to configure placeholder nodes for both the predictor and target variates (i.e. $X$ and $\\vec{y}$). Note that in the `shape` argument, we explicitly used **`None`** to inform TensorFlow that we wish to leave the dimension as ambiguous. Doing so allows us to feed data into our graph with an arbitrary number of observations (i.e. we don't have to worry about adhering to size specifications). This becomes increasingly important when performing mini-bath gradient descent, or when we want to make predictions on new datasets with varying lengths. In this step, we also convert the y values to 'one hot encoding' using `tf.one_hot`\n",
    "    \n",
    "**Step 3: Add variable nodes for weights**\n",
    "\n",
    "- Here we configure variables for the values we wish to train (i.e. our weight parameters) and initialize them (assign initial values) using the `glorot_normal` initializer. We will cover initialization techniques in more detail in module 11, for now all you need to know is that glorot initialization is generally a good default technique for most models. Note that our variable dimensions will be `[n, n_classes]` (i.e. the number of features & the number of classes in the data) as is standard for softmax regression. \n",
    "    \n",
    "**Step 4: Calculate variables and outputs**\n",
    "\n",
    "- Now we will calculate the *logit* values (i.e.the  logarithm of the odds of an event occuring), the softmax output, and the log loss. These will all be done using TensorFlow's available arithmetic operations.\n",
    "    \n",
    "**Step 5: Gardient descent calculations**\n",
    "\n",
    "- Lastly, we will calculate the gradients and update the $W$ node (i.e. the weights vector) using `tf.assign`. Remember that a variable in TensorFlow will persist between runs so long as the session is not closed in between (the values are stored in the **session** and not the graph itself).\n",
    "    \n",
    "We now implement the algorithm presented above as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bf7aCMss3ePY"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'glorot_uniform_initializer' from 'tensorflow' (C:\\Users\\bruno.gonzalez\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-c762c20bcd3a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mglorot_uniform_initializer\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreset_default_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m# STEP 1: Set the values for hyperparameters\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mImportError\u001B[0m: cannot import name 'glorot_uniform_initializer' from 'tensorflow' (C:\\Users\\bruno.gonzalez\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import glorot_uniform_initializer\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# STEP 1: Set the values for hyperparameters\n",
    "m, n = X_train.shape \n",
    "# number of classes based on the data\n",
    "n_classes = len(np.unique(y_train))\n",
    "# learning and epsilon will be arbitrary for now\n",
    "learning_rate = 0.01\n",
    "# epsilon is added to loss function\n",
    "epsilon = 1e-7\n",
    "\n",
    "# STEP 2: Add placeholder nodes for inputs\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n))\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None))\n",
    "# apply one hot encoding to the data\n",
    "y_one_hot = tf.one_hot(y, n_classes)\n",
    "\n",
    "# STEP 3: Add variable nodes for weights\n",
    "# Initial value will be based on random normal distribution\n",
    "W = tf.get_variable(name='weights', shape=(n, n_classes), initializer=glorot_uniform_initializer)\n",
    "\n",
    "# STEP 4: Calculate softmax outputs\n",
    "logits = tf.matmul(X, W)\n",
    "# use tf.reshape to convert to column vector\n",
    "y_proba = tf.exp(logits) / tf.reshape(tf.reduce_sum(tf.exp(logits), axis = -1), (-1, 1))\n",
    "log_loss = -tf.reduce_mean(tf.reduce_sum(y_one_hot * tf.log(y_proba + epsilon), axis = -1))\n",
    "\n",
    "# STEP 5: Gradient descent calculations\n",
    "error = y_proba - y_one_hot\n",
    "gradients = 1/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(W, W - learning_rate * gradients)\n",
    "\n",
    "# Initialize all variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kHGysQE_3ePa"
   },
   "source": [
    "The graph constructed above is merely an implementation of the algorithm described earlier for calculating the gradients. If we were to run a few iterations of this graph, we would essentially be running our own version of **gradient descent**. Similar to what we did in the previous module, to run the graph we would have to open a session and evaluate the `training_op` variable node. Doing so will evaluate the computation graph and adjust the weight parameters accordingly.\n",
    "\n",
    "Evaluating the graph is essentially the main goal of the **execution phase**. However, we will omit the details until later. As of now, we will ensure that the implementation is indeed correct by evaluating a session run. We would expect the loss to decrease after each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1562796921925,
     "user": {
      "displayName": "Michael Ciniello",
      "photoUrl": "https://lh4.googleusercontent.com/-Sc81UFAmWWE/AAAAAAAAAAI/AAAAAAAAInI/ccJjIOAmlUo/s64/photo.jpg",
      "userId": "09099206197539783636"
     },
     "user_tz": 240
    },
    "id": "cbrxNp_l3ePb",
    "outputId": "bac9f660-2d53-4a78-a43c-939aa2a9ad93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9201262\n",
      "2.8979502\n",
      "2.8759534\n",
      "2.854136\n",
      "2.8324976\n",
      "2.8110366\n",
      "2.7897544\n",
      "2.7686496\n",
      "2.7477214\n",
      "2.72697\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "losses = []\n",
    "for i in range(10):\n",
    "    _, loss = sess.run([training_op, log_loss], feed_dict={X:X_train, y:y_train})\n",
    "    print(loss)\n",
    "    losses.append(loss)\n",
    "    \n",
    "plt.plot(losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-E0oXBF3ePe"
   },
   "source": [
    "## Using `tf.autodiff`\n",
    "\n",
    "From the most recent example, you may notice that the loss looks to be decreasing within the first five iterations. This is the behaviour that we would expect for a correctly implemented gradient descent algorithm. In fact, deriving the gradients for specific models (i.e. softmax regression, linear regression) may prove to be simple. However, this is not the case for complex models (i.e. neural networks). In the case of a multi-layer neural network, one would consider using symbolic differentiation to automatically determine the equations for the partial derivatives. But the code involved to implement such equations directly would not necessarily be the most efficient approach. \n",
    "\n",
    "**Example of Associated Inefficiencies:**\n",
    "\n",
    "To illustrate this reasoning, consider some function $f(x) = \\exp(\\exp(\\exp(x)))$ (recall that the $\\exp(x)$ function is equivalent to $e^x$). The first derivative can easily be calculated as $f'(x) = \\exp(\\exp(\\exp(x)))\\cdot\\exp(\\exp(x))\\cdot\\exp(x)$ using the *Chain Rule*. If one were to implement $f(x)$ and $f'(x)$ exactly as they appeared in the equation, the approach will not be optimal since $f'(x)$ alone requires six separate calls to `exp(...)`. Furthermore, $f(x)$ would require three additional calls to the same function (which totals to nine calls among these two equations).\n",
    "\n",
    "A more efficient proposal would be to create a function that first calculates $\\exp(x)$. Then using that value, compute $\\exp(\\exp(x))$ and from that, compute $\\exp(\\exp(\\exp(x)))$. These three values can then be returned as a triplet. That is, we are returning $\\left(\\exp(x), \\exp(\\exp(x)), \\exp(\\exp(\\exp(x)))\\right)$. Note that the last term in this triple is our original $f(x)$. We can also easily derive $f'(x)$ by multiplying all three terms together. Hence we only require a total of three calls to `exp(...)` in this implementation as opposed to nine when directly implementing the equations.\n",
    "\n",
    "The direct approach also fails to capture the scenario when the function itself is not known, or if it is embedded within some code. For example, imagine computing the derivative for $f(x)$ defined below:\n",
    "\n",
    "    def my_func(a, b):\n",
    "        z = 0\n",
    "        for i in range(100):\n",
    "            z = a * np.cos(z + i) + z * np.sin(b - i)\n",
    "        return z\n",
    "\n",
    "This is indeed a daunting task (we don't recommend that you try!). Fortunately, the `autodiff` feature available in TensorFlow allows us to efficiently calculate the gradients of the function for us. We will update our code to accommodate for this by replacing:\n",
    "\n",
    "    error = y_proba - y_one_hot\n",
    "    gradients = 1/m * tf.matmul(tf.transpose(X),error)\n",
    "\n",
    "with the far simpler code:\n",
    "\n",
    "    gradients = tf.gradients(log_loss,W)[0] # extract gradients using autodiff\n",
    "    \n",
    "We also have the luxury of replacing the manual calculations for our probabilities and losses with the equivalent built in TensorFlow versions, which is more highly optimized (though the results should be the exact same):\n",
    "\n",
    "    y_proba = tf.nn.softmax(logits)\n",
    "    log_loss = tf.losses.log_loss(y_one_hot, y_proba)\n",
    "\n",
    "With all the changes introduced above, we will merge everything together and update our softmax model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nj0zXA9b3ePe"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "m, n = X_train.shape \n",
    "n_classes = len(np.unique(y_train))\n",
    "learning_rate = 0.01\n",
    "epsilon = 1e-7 \n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n))\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None))\n",
    "y_one_hot = tf.one_hot(y, n_classes)\n",
    "\n",
    "W = tf.get_variable(name='weights', shape=(n, n_classes), initializer=random_normal)\n",
    "logits = tf.matmul(X, W)\n",
    "\n",
    "# This is the updated code segment replacing all the prior implementations\n",
    "# with the equivalent versions offered in TensorFlow\n",
    "y_proba = tf.nn.softmax(logits)\n",
    "log_loss = tf.losses.log_loss(y_one_hot, y_proba)\n",
    "gradients = tf.gradients(log_loss,W)[0]\n",
    "training_op = tf.assign(W, W - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WKi6w25P3ePg"
   },
   "source": [
    "For sanity purposes, we will rerun the algorithm again to verify that the behaviour is intact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q0kwybrL3ePh",
    "outputId": "7d525887-3cb2-43f5-d0f7-9b4f2adfde9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2968947\n",
      "1.2966384\n",
      "1.2963773\n",
      "1.2961138\n",
      "1.2958546\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(5):\n",
    "    _, loss = sess.run([training_op, log_loss], feed_dict={X:X_train, y:y_train})\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vd2Gw2Fr3ePj"
   },
   "source": [
    "Evidently, computing gradients using `tf.gradients` proves to be far easier than manually deriving them.\n",
    "\n",
    "Below is a list of the **main approaches to computing gradients automatically.** As mentioned above, Tensorflow uses reverse-mode autodiff, which works best (in terms of efficiency and accuracy) when there are a high number of inputs and only few outputs (which is usually the case for most deep learning applications). Reverse-mode autodiff can compute all of the partial derivatives of the outputs with regards to all the inputs in just **n outputs + 1 graph traversals**. \n",
    "\n",
    "<div style=\"text-align:center;margin:15px;\">\n",
    "<img src='./images/c4_m9_p1_graph5.png' style=\"float:left;width:300;height:200;\">\n",
    "</div>\n",
    "\n",
    "Image Description: Overview of main differentiation techniques for neural networks\n",
    "\n",
    "Image source: Géron, A. (2017). Chapter 9: Up and Running with TensorFlow in Hands-On Machine Learning with Scikit-Learn and TensorFlow, O’Reilly Media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z775W22p3ePk"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We won't go into the heavy details of how these techniques work, as they require a solid understanding of calculus and are somewhat out of scope for our purposes. That said, you are encouraged to dig more into these concepts yourself! \n",
    "Aurélien Geron oﬀers an excellent introduction to the topic on his Github (https://github.com/ageron/handson-ml/blob/master/extra_autodiﬀ.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S47T35tz3ePk"
   },
   "source": [
    "## Using `tf.train` optimizers\n",
    "\n",
    "On top of `autodiff`, TensorFlow also offers a number of optimiziers to be used out of the box. Such optimiziers include a Gradient Descent optimizer. To use this optimizer, we would have to replace the following code:\n",
    "\n",
    "    gradients = tf.gradients(log_loss,W)[0] \n",
    "    training_op = tf.assign(W, W - learning_rate * gradients)\n",
    "    \n",
    "with the corresponding simplified version:\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss=log_loss)\n",
    "\n",
    "The training optimizer will trace through the computation graph associated to its input (i.e. loss) and look out for variable nodes. For every variable node that it encounters, it calculates the gradient of the loss with respect to that specific variable. From there, it computes a new value for the variable defined as\n",
    "\n",
    "$$\n",
    "\\text{new value} = \\text{current value} - \\text{gradient}\\times\\text{learning rate}\n",
    "$$\n",
    "\n",
    "Finally, it updates the variable with the new value through an assign operation. So to summarize, when you call `sess.run(training_op)`, the optimizer performs a step of gradient descent for **all** of the variables automatically. However, we would still need to provide the accommodating input and output placeholders. It is also recommended to print the calculated losses as this can help useful for debugging purposes.\n",
    "\n",
    "Notice that when initializing an optimizer, we call the `minimize` method which takes in some cost function as an argument. It is this cost function that the optimizier attempts to minimize (i.e. in this case, we passed the `log_loss` tensor as the argument).\n",
    "\n",
    "The code segment below summarizes all of our optimizations throughout this section (where we converted essentially all of our manual operations to the built-in equivalents in TensorFlow). Also note that we attempted to simplify the code by wrapping `y_proba` and `log_loss` into the single `tf.nn.softmax_cross_entropy_with_logits_v2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mt9gOSjr3ePl"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "m, n = X_train.shape \n",
    "n_classes = len(np.unique(y_train))\n",
    "learning_rate = 0.01\n",
    "epsilon = 0.1 # to prevent underflow\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n))\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None))\n",
    "y_one_hot = tf.one_hot(y, n_classes)\n",
    "\n",
    "W = tf.get_variable(name='weights', shape=(n, n_classes), initializer=random_normal)\n",
    "logits = tf.matmul(X, W)\n",
    "\n",
    "# Updated code using more efficient built in tf functions\n",
    "log_loss = tf.losses.softmax_cross_entropy(onehot_labels=y_one_hot, logits=logits)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(log_loss)\n",
    "\n",
    "init = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JaGEDRMk3ePm"
   },
   "source": [
    "Now we will run five iterations of our most recent version of the model for sanity purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UXamI_WZ3ePn",
    "outputId": "d641ce70-9777-4f30-8c54-c253ae74d7d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.930599\n",
      "9.908997\n",
      "9.887437\n",
      "9.865914\n",
      "9.844434\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(5):\n",
    "    _, loss = sess.run([training_op, log_loss], feed_dict={X:X_train, y:y_train})\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NTNKsC343ePp"
   },
   "source": [
    "# Model Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s1I2ftXB3ePq"
   },
   "source": [
    "## Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z4Eoscnw3ePq"
   },
   "source": [
    "From the prior section, you should be familiar with the general flow on how to proceed with developing a graph using TensorFlow's optimizers. Now we will focus more on the **execution phase** of the model development process. Recall that **batch gradient descent** involves training your model with the entire training data set at once.\n",
    "\n",
    "Model execution is as simple as **setting the number of epochs we want to run our model for**, and looping through the graph re-running the `training_op` each time. This will iteratively recalculate the gradients, and also update the `W` values, thus performing gradient descent. Once the algorithm is finished, you would ideally keep a copy of the weight tensors so you can make predictions later on if necessary.\n",
    "\n",
    "The code segment below generalizes the training portion of our model into a single function. It is ideal to segregate different stages of model development into functions not only for readibility, but to also keep your workflow organized for easy debugging and development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kpZb9QRg3ePr"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, epochs=2500):\n",
    "    # Open a session\n",
    "    with tf.Session() as sess:\n",
    "        # Initialize variables\n",
    "        sess.run(init)\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        # Loop through the graph for n epochs\n",
    "        for epoch in range(epochs):\n",
    "            # Update weights and save W_update for later!\n",
    "            _, train_loss, W_update = sess.run([training_op, log_loss, W], feed_dict={X:X_train, y:y_train})\n",
    "            # Get validation loss\n",
    "            val_loss = sess.run(log_loss, feed_dict={X:X_val, y:y_val})\n",
    "            # Save incremental loss values for visualization\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            # Print results evey 100 runs\n",
    "            if epoch % 250 == 0:\n",
    "                print(\"Epoch\", epoch, \"Train Loss =\", train_loss, \"Validation Loss =\", val_loss)\n",
    "    # Plot loss values\n",
    "    plt.plot(train_losses, label='training loss')\n",
    "    plt.plot(val_losses, label='validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return updated weights\n",
    "    return W_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tNE3JGGZ3ePs"
   },
   "source": [
    "Using the training function above, we will reconstruct our model code again to accommodate for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBwlvM1X3ePt",
    "outputId": "cd668cc9-90d4-42c9-b7f9-7f001957c48d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train Loss = 11.684042 Validation Loss = 10.918069\n",
      "Epoch 250 Train Loss = 5.7501626 Validation Loss = 5.332797\n",
      "Epoch 500 Train Loss = 3.1337829 Validation Loss = 2.9330277\n",
      "Epoch 750 Train Loss = 2.132646 Validation Loss = 2.007855\n",
      "Epoch 1000 Train Loss = 1.6461794 Validation Loss = 1.5443257\n",
      "Epoch 1250 Train Loss = 1.3577276 Validation Loss = 1.2667372\n",
      "Epoch 1500 Train Loss = 1.1607339 Validation Loss = 1.0800648\n",
      "Epoch 1750 Train Loss = 1.0170166 Validation Loss = 0.94696975\n",
      "Epoch 2000 Train Loss = 0.90698147 Validation Loss = 0.8494229\n",
      "Epoch 2250 Train Loss = 0.8188884 Validation Loss = 0.7740308\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################### MODEL CONSTRUCTION ####################################\n",
    "tf.reset_default_graph()\n",
    "m, n = X_train.shape \n",
    "n_classes = len(np.unique(y_train))\n",
    "learning_rate = 0.01\n",
    "epsilon = 0.1 # to prevent underflow (division by zero when values become too small)\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n))\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None))\n",
    "y_one_hot = tf.one_hot(y, n_classes)\n",
    "\n",
    "W = tf.get_variable(name='weights', shape=(n, n_classes), initializer=random_normal)\n",
    "logits = tf.matmul(X, W)\n",
    "# Add in y_proba node so it can be called to make predictions later on\n",
    "y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "log_loss = tf.losses.softmax_cross_entropy(onehot_labels=y_one_hot, logits=logits)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(log_loss)\n",
    "init = tf.global_variables_initializer() \n",
    "\n",
    "#################################### MODEL EXECUTION ####################################\n",
    "W_update = train_model(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wbr8F6rc3ePv"
   },
   "source": [
    "Again, both the training and validation losses decrease per iteration. This is what we should expect as we are solving a simple convex optimization problem (a function is considered [convex](https://en.wikipedia.org/wiki/Convex_function),  if the line segment between any two points on the graph of the function lies above or on the graph ).\n",
    "\n",
    "Now we wish to use the trained model to make predictions. Recall that all values in a TensorFlow graph are cleared once a session is closed, and thus we cannot simply run the `y_proba` node as we would be trying to run the model using uninitialized variables. This is why we return the trained weights node $W$ in the function above. \n",
    "\n",
    "Before proceeding, we will double check to make sure the updated weight parameters have the proper dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ki1IjC0k3ePw",
    "outputId": "5180dddd-bef9-469e-b101-3f409e74c9fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias shape: (10,)\n",
      "coefficients shape: (64, 10)\n"
     ]
    }
   ],
   "source": [
    "print('bias shape:', W_update[0].shape)\n",
    "print('coefficients shape:', W_update[1:].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r3g3VJfM3ePy"
   },
   "source": [
    "To proceed with predictions, we will need to first feed the most updated weight values into the graph using `tf.assign`. We will also use a confusion matrix to briefly get a sense of how the model is performing. Again, we will wrap this code in a function to easily make predictions for future models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4kqNnsh23ePy",
    "outputId": "56c96830-dcb9-45cd-c3a0-920d73e745e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8497495826377296\n",
      "Confusion Matrix:\n",
      " [[164   0   1   2   0   2   5   1   3   0]\n",
      " [  0 150   5   0   6   1   4   4   6   6]\n",
      " [  2   5 155  11   1   0   1   1   1   0]\n",
      " [  0   4   0 151   0   4   0   2  12  10]\n",
      " [  2   3   0   0 169   0   1   3   1   2]\n",
      " [  2   4   2   3   0 165   0   1   1   4]\n",
      " [  1   3   0   0   2   4 170   0   1   0]\n",
      " [  3   0   1   4   3   0   0 164   4   0]\n",
      " [  0  15   5   9   2   7   4   5 112  15]\n",
      " [  5  10   0  12   3   8   2   5   8 127]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def make_predictions(X_test, y_test, W_update):\n",
    "    \"\"\"Use trained model weights to make predictions\"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        # Note that you could also simple enter 'W:W_update' into the feed_dict argument below \n",
    "        sess.run(tf.assign(W, W_update))\n",
    "        # Feed in the test data and select the high probability as the prediction\n",
    "        predictions = sess.run(tf.argmax(y_proba, axis=-1), feed_dict={X:X_test})\n",
    "    # Show the confusion matrix\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "    print(\"Confusion Matrix:\\n\",confusion_matrix(y_test, predictions))\n",
    "\n",
    "make_predictions(X_mnist, y_mnist, W_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8qyEZmk3eP0"
   },
   "source": [
    "## Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPJ7-J5Z3eP1"
   },
   "source": [
    "In **mini-batch gradient descent**, we train the model repeatedly on smaller subsets of the entire training data as opposed to the full training set itself. This can easily be implemented in our code by iterating through random subsets of the training data at each epoch.\n",
    "\n",
    "For convenience, we implement the batch splitting algorithm as its own function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oe0Lz_iO3eP2"
   },
   "outputs": [],
   "source": [
    "def fetch_batch(batch_size):\n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    X_batch = X_train[indices]\n",
    "    y_batch = y_train[indices]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tGK3BChi3eP5"
   },
   "source": [
    "Now we will update our prior `train_model` function to accommodate for mini-batch training. You should expect training to take a little longer as we now have extra iterations within each epoch depending on the batch size. This will contribute to algorithmic complexity greatly depending on how large the batch sizes are relative to how large the training set is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OId5aUMl3eP6",
    "outputId": "dda7764e-144e-4716-9d12-74c9dfd5d3d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train Loss = 10.662371 Validation Loss = 10.924294\n",
      "Epoch 250 Train Loss = 1.4221576 Validation Loss = 1.5215482\n",
      "Epoch 500 Train Loss = 0.7077136 Validation Loss = 0.86859876\n",
      "Epoch 750 Train Loss = 0.48680604 Validation Loss = 0.671228\n",
      "Epoch 1000 Train Loss = 0.3757375 Validation Loss = 0.56824166\n",
      "Epoch 1250 Train Loss = 0.30439833 Validation Loss = 0.50459135\n",
      "Epoch 1500 Train Loss = 0.25393933 Validation Loss = 0.4627774\n",
      "Epoch 1750 Train Loss = 0.21544799 Validation Loss = 0.43260562\n",
      "Epoch 2000 Train Loss = 0.1850494 Validation Loss = 0.4095011\n",
      "Epoch 2250 Train Loss = 0.16135229 Validation Loss = 0.39164785\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8497495826377296\n",
      "Confusion Matrix:\n",
      " [[164   0   1   2   0   2   5   1   3   0]\n",
      " [  0 150   5   0   6   1   4   4   6   6]\n",
      " [  2   5 155  11   1   0   1   1   1   0]\n",
      " [  0   4   0 151   0   4   0   2  12  10]\n",
      " [  2   3   0   0 169   0   1   3   1   2]\n",
      " [  2   4   2   3   0 165   0   1   1   4]\n",
      " [  1   3   0   0   2   4 170   0   1   0]\n",
      " [  3   0   1   4   3   0   0 164   4   0]\n",
      " [  0  15   5   9   2   7   4   5 112  15]\n",
      " [  5  10   0  12   3   8   2   5   8 127]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, epochs=2500, batch_size=300):\n",
    "    # Open a session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Initialize loss values\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        # Initialize batch values\n",
    "        m = len(X_train)\n",
    "        batches = int(m/batch_size)\n",
    "        \n",
    "        # Loop through the graph for n epochs\n",
    "        for epoch in range(epochs):\n",
    "            # Loop through the mini-batches\n",
    "            for batch in range(batches):\n",
    "                # Fetch a new batch\n",
    "                X_batch, y_batch = fetch_batch(batch_size)\n",
    "                # Run the training op\n",
    "                sess.run([training_op], feed_dict={X:X_batch, y:y_batch})\n",
    "            # Get trianing/validation loss\n",
    "            train_loss = sess.run(log_loss, feed_dict={X:X_train, y:y_train})\n",
    "            val_loss = sess.run(log_loss, feed_dict={X:X_val, y:y_val})\n",
    "            # Save incremental loss values for visualization\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            if epoch % 250 == 0:\n",
    "                print(\"Epoch\", epoch, \"Train Loss =\", train_loss, \"Validation Loss =\", val_loss)\n",
    "    # Plot loss values\n",
    "    plt.plot(train_losses, label='training loss')\n",
    "    plt.plot(val_losses, label='validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return updated weights\n",
    "    return W_update\n",
    "\n",
    "W_update = train_model(X_train, y_train, X_val, y_val)\n",
    "make_predictions(X_mnist, y_mnist, W_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H8UBuzfd3eP9"
   },
   "source": [
    "## Saving and Restoring models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CmChXoSj3eP-"
   },
   "source": [
    "Recall in the previous module we briefly discussed how to save and load graphs in TensorFlow. We will extend this functionality to save our current MNIST classification model. To accomplish this, we just need to create a new `tf.train.saver()` node after we have constructed our graph (i.e. after all variable nodes are created). Once we reach the execution phase, we can then call `save()` whenever we want to save the model. Doing so will require us to pass the saver with both the session and the path of where we wish to save the model components.\n",
    "\n",
    "It is important to recognize that we ideally want to save our model at regular intervals throughout training. This ensures that our progress can be recovered in the case that something goes wrong during training. If the model is recoverable, we can proceed from when it was last saved as opposed to starting from the very beginning.\n",
    "\n",
    "Now we will update our `train_model` function to include saving (in this case, we will save after every 250 epochs or iterations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lMvLP3lm3eP_"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, saver, epochs=2500, batch_size=300, save_path='./models/my_softmax_model.model'):\n",
    "    # Open a session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Initialize loss values\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        # Initialize batch values\n",
    "        m = len(X_train)\n",
    "        batches = int(m/batch_size)\n",
    "        \n",
    "        # Loop through the graph for n epochs\n",
    "        for epoch in range(epochs):\n",
    "            # Loop through the mini-batches\n",
    "            for batch in range(batches):\n",
    "                # Fetch a new batch\n",
    "                X_batch, y_batch = fetch_batch(batch_size)\n",
    "                # Run the training op\n",
    "                sess.run([training_op], feed_dict={X:X_batch, y:y_batch})\n",
    "            # Get training/validation loss\n",
    "            train_loss = sess.run(log_loss, feed_dict={X:X_train, y:y_train})\n",
    "            val_loss = sess.run(log_loss, feed_dict={X:X_val, y:y_val})\n",
    "            # Save incremental loss values for visualization\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            # Save model and print results at 250 epochs\n",
    "            if epoch % 250 == 0:\n",
    "                saver.save(sess, save_path)\n",
    "                print(\"Epoch\", epoch, \"Train Loss =\", train_loss, \"Validation Loss =\", val_loss)\n",
    "        # Save final model\n",
    "        saver.save(sess, save_path)\n",
    "    # Plot loss values\n",
    "    plt.plot(train_losses, label='training loss')\n",
    "    plt.plot(val_losses, label='validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return updated weights\n",
    "    return W_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvWAZSnb3eQA"
   },
   "source": [
    "With our training function modified, we now need to add a `tf.train.Saver()` object at the end of the code segment where we finish creating our model graph. Note that with our specified saved path, we save the model in ***/models/*** every 250 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wTpSWVT3eQA",
    "outputId": "114a8331-c913-421a-cb74-2ca567770936"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train Loss = 12.681422 Validation Loss = 12.972495\n",
      "Epoch 250 Train Loss = 1.6180229 Validation Loss = 1.8856086\n",
      "Epoch 500 Train Loss = 0.83298486 Validation Loss = 1.076474\n",
      "Epoch 750 Train Loss = 0.55128056 Validation Loss = 0.77666694\n",
      "Epoch 1000 Train Loss = 0.39828655 Validation Loss = 0.6214355\n",
      "Epoch 1250 Train Loss = 0.30339167 Validation Loss = 0.52774954\n",
      "Epoch 1500 Train Loss = 0.24667947 Validation Loss = 0.46829095\n",
      "Epoch 1750 Train Loss = 0.20711242 Validation Loss = 0.42745832\n",
      "Epoch 2000 Train Loss = 0.17987935 Validation Loss = 0.39824453\n",
      "Epoch 2250 Train Loss = 0.15975729 Validation Loss = 0.37596935\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8497495826377296\n",
      "Confusion Matrix:\n",
      " [[164   0   1   2   0   2   5   1   3   0]\n",
      " [  0 150   5   0   6   1   4   4   6   6]\n",
      " [  2   5 155  11   1   0   1   1   1   0]\n",
      " [  0   4   0 151   0   4   0   2  12  10]\n",
      " [  2   3   0   0 169   0   1   3   1   2]\n",
      " [  2   4   2   3   0 165   0   1   1   4]\n",
      " [  1   3   0   0   2   4 170   0   1   0]\n",
      " [  3   0   1   4   3   0   0 164   4   0]\n",
      " [  0  15   5   9   2   7   4   5 112  15]\n",
      " [  5  10   0  12   3   8   2   5   8 127]]\n"
     ]
    }
   ],
   "source": [
    "#################################### MODEL CONSTRUCTION ####################################\n",
    "tf.reset_default_graph()\n",
    "m, n = X_train.shape \n",
    "n_classes = len(np.unique(y_train))\n",
    "learning_rate = 0.01\n",
    "epsilon = 0.1 # to prevent underflow\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n), name='X')\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None), name='y')\n",
    "y_one_hot = tf.one_hot(y, n_classes)\n",
    "\n",
    "W = tf.get_variable(name='weights', shape=(n, n_classes), initializer=random_normal)\n",
    "logits = tf.matmul(X, W)\n",
    "y_proba = tf.nn.softmax(logits, name='predict')\n",
    "\n",
    "log_loss = tf.losses.softmax_cross_entropy(onehot_labels=y_one_hot, logits=logits)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(log_loss)\n",
    "init = tf.global_variables_initializer() \n",
    "\n",
    "# Add the saver\n",
    "saver = tf.train.Saver() \n",
    "\n",
    "#################################### MODEL EXECUTION ####################################\n",
    "W_update = train_model(X_train, y_train, X_val, y_val, saver=saver)\n",
    "make_predictions(X_mnist, y_mnist, W_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "suibM2sT3eQD"
   },
   "source": [
    "The saver gives us some flexibility in choosing what variables we wish to save. By default, the saver will save and restore all variables present in the graph under their respective names. To specify which variables to save and/or restore and what names to map them to, consider the following:\n",
    "\n",
    "    saver = tf.train.Saver({\"weights\": theta})\n",
    "    \n",
    "The saver above will complete save and restore operations that only correspond to `theta` and map it to the name \"weights\". You are encouraged to use this feature at your own discretion depending on what you wish to preserve. For the time being, we will attempt to reload our trained model and make some predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lfRPxgz_3eQE",
    "outputId": "ffe881c7-d253-4f35-fc05-e5d28ace3d41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/my_softmax_model.model\n",
      "Restored weights shape: (65, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9305555555555556"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "# this loads the graph structure\n",
    "saver = tf.train.import_meta_graph('./models/my_softmax_model.model.meta')\n",
    "# get the specific tensors with corresponding name\n",
    "weights = graph.get_tensor_by_name('weights:0')\n",
    "X = graph.get_tensor_by_name('X:0')\n",
    "predict = graph.get_tensor_by_name('predict:0') \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # load the state of the model\n",
    "    saver.restore(sess, './models/my_softmax_model.model')\n",
    "    print(\"Restored weights shape:\",weights.eval().shape)\n",
    "    predictions = np.argmax(sess.run(predict, feed_dict={X:X_val}), axis=1)\n",
    "    \n",
    "# Calculate the accuracy of our predictions\n",
    "accuracy_score(y_val, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wk1QhtP53eQG",
    "toc-hr-collapsed": true
   },
   "source": [
    "## Exercise\n",
    "\n",
    "Leveraging the examples above, try building your own linear regression model using TensorFlow. You will be working with sklearn's **California housing price prediction** dataset, which we have loaded for you below. This exercise will involve 3 components:\n",
    "1. Constructing your tf graph for the linear regression\n",
    "2. Building the function to train the model\n",
    "3. Building the function to make predictions\n",
    "\n",
    "Save the functions as `train_model_linreg` and `make_predictions_linreg` so as to not overwrite our softmax model above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WVnHiYS3eQH",
    "outputId": "2d1718cd-da7e-4e4a-cd70-e86ca4e75c59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block\n",
      "        - HouseAge      median house age in block\n",
      "        - AveRooms      average number of rooms\n",
      "        - AveBedrms     average number of bedrooms\n",
      "        - Population    block population\n",
      "        - AveOccup      average house occupancy\n",
      "        - Latitude      house block latitude\n",
      "        - Longitude     house block longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "http://lib.stat.cmu.edu/datasets/\n",
      "\n",
      "The target variable is the median house value for California districts.\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import california_housing\n",
    "housing = california_housing.fetch_california_housing()\n",
    "print(housing.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKThEhRo3eQI",
    "outputId": "e3e9238c-663a-4b64-88c8-32d5d522b513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (16512, 9)\n",
      "X_val: (4128, 9)\n",
      "y_train: (16512, 1)\n",
      "y_val: (4128, 1)\n"
     ]
    }
   ],
   "source": [
    "X_housing = housing[\"data\"]\n",
    "y_housing = housing[\"target\"]\n",
    "scaler = StandardScaler()\n",
    "X_housing = scaler.fit_transform(X_housing)\n",
    "X_housing = np.c_[np.ones((X_housing.shape[0],1)), X_housing]\n",
    "X_housing_train, X_housing_val, y_housing_train, y_housing_val = train_test_split(X_housing, y_housing, test_size=0.2, shuffle=True)\n",
    "y_housing_train = y_housing_train.reshape(-1,1)\n",
    "y_housing_val= y_housing_val.reshape(-1,1)\n",
    "\n",
    "print(\"X_train:\", X_housing_train.shape)\n",
    "print(\"X_val:\", X_housing_val.shape)\n",
    "print(\"y_train:\", y_housing_train.shape)\n",
    "print(\"y_val:\", y_housing_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TNc10gcJ3eQK"
   },
   "source": [
    "### Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d5nZ3oQN3eQL"
   },
   "outputs": [],
   "source": [
    "# Construct linear regression Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x6_GOKjY3eQM"
   },
   "outputs": [],
   "source": [
    "# Build your train_model function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCiSkDWJ3eQO"
   },
   "outputs": [],
   "source": [
    "# Build you make_predictions function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7zLx9_dI3eQP"
   },
   "outputs": [],
   "source": [
    "# Train your model and make predcitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghLGtW7d3eQR"
   },
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmcVY2sq3eQR"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Build graph\n",
    "tf.reset_default_graph()\n",
    "m, n = X_housing_train.shape \n",
    "learning_rate = 0.01\n",
    "epsilon = 0.1 # to prevent underflow\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n))\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None,1))\n",
    "\n",
    "W = tf.get_variable(name='weights', shape=(n,1), initializer=random_normal)\n",
    "y_pred = tf.matmul(X, W)\n",
    "\n",
    "mse = tf.losses.mean_squared_error(labels=y, predictions=y_pred)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VKgcjm9-3eQT",
    "outputId": "a9c5ee67-8417-4d8d-af9e-7936afd12af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train Loss = 4.6974964 Validation Loss = 4.663599\n",
      "Epoch 250 Train Loss = 0.84552336 Validation Loss = 0.9139853\n",
      "Epoch 500 Train Loss = 0.7516865 Validation Loss = 0.8118078\n",
      "Epoch 750 Train Loss = 0.7068341 Validation Loss = 0.7676641\n",
      "Epoch 1000 Train Loss = 0.68507195 Validation Loss = 0.74834657\n",
      "Epoch 1250 Train Loss = 0.67434704 Validation Loss = 0.73997986\n",
      "Epoch 1500 Train Loss = 0.6689597 Validation Loss = 0.73637414\n",
      "Epoch 1750 Train Loss = 0.6661916 Validation Loss = 0.734794\n",
      "Epoch 2000 Train Loss = 0.66473234 Validation Loss = 0.73405075\n",
      "Epoch 2250 Train Loss = 0.6639416 Validation Loss = 0.7336429\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build train_model function\n",
    "import matplotlib.pyplot as plt\n",
    "def train_model_linreg(X_train, y_train, X_val, y_val, epochs=2500):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        for epoch in range(epochs):\n",
    "            _, train_loss, W_update = sess.run([training_op, mse, W], feed_dict={X:X_train, y:y_train})\n",
    "            val_loss = sess.run(mse, feed_dict={X:X_val, y:y_val})\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            if epoch % 250 == 0:\n",
    "                print(\"Epoch\", epoch, \"Train Loss =\", train_loss, \"Validation Loss =\", val_loss)\n",
    "    plt.plot(train_losses, label='training loss')\n",
    "    plt.plot(val_losses, label='validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return W_update\n",
    "\n",
    "W_trained = train_model_linreg(X_housing_train, y_housing_train, X_housing_val, y_housing_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rXJbO_803eQW",
    "outputId": "5e37d25b-d2c9-476a-8f5c-c670cc4fc842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.7846815811395077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def make_predictions_linreg(X_test, y_test, W_trained):\n",
    "    \"\"\"Use trained model weights to make predictions\"\"\"\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.assign(W, W_trained))\n",
    "        predictions = sess.run(y_pred, feed_dict={X:X_test})\n",
    "    print(\"Mean squared error:\", mean_squared_error(y_test, predictions))\n",
    "\n",
    "make_predictions_linreg(X_housing, y_housing, W_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4I0PhTc3eQX"
   },
   "source": [
    "# Visualizing Models with Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPUalkYG3eQY"
   },
   "source": [
    "## Overview of Tensorboard and Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oPmPaa_h3eQY"
   },
   "source": [
    "As of now, we have successfully implemented a computation graph and run several training epochs for a softmax classifier using mini-batch gradient descent. Furthermore, we are saving our model at regular training intervals using the `tf.trian.saver` module. If you've gotten this far, you now know enough about TensorFlow to build your own machine learning models! You are encouraged to try running these simple TensorFlow models on new datasets, and leverage the documentation to build more diverse and sophisticated models (which we will be doing in the next module). For now, let's move on to the next topic in this module; **model visualization using Tensorboard**.\n",
    "\n",
    "TensorBoard allows the user to display interactive visualizations of a model's graph structure and its training outputs, all through a simple web browser interface. The user can easily interact with and drill down into their graph structure through intuitive visualizations, which can be incredibly helpful when trying to identify bugs or issues with your model architecture.\n",
    "\n",
    "To get started with TensorBoard, we need to make note of the following:\n",
    "- We need to tweak our `train_model` function to record training statistics (MSE, loss, train_error, val_error, etc.) at regular intervals. We will record these details in a log file using the `tf.summary.FileWriter` function.\n",
    "- Every time we run the program, we need to revert to a different log directory. Otherwise, TensorFlow will automatically merge the statistics of different runs and will ultimately corrupt the visualizations we see in TensorBoard.\n",
    "\n",
    "In order to avoid the cross-contamination of log files, we can easily append timestamps to the filenames to ensure that the statistics of each model run are saved in a unique log file. The following code segment achieves this:\n",
    "    \n",
    "        from datetime import datetime\n",
    "        now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "        root_logdir = \"tf_logs\"\n",
    "        logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "We would also need to add the following at the end of our model construction phase code:\n",
    "    \n",
    "        logloss_summary = tf.summary.scalar('log_loss', log_loss)\n",
    "        file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "    \n",
    "The first line adds a new node in the graph that is responsible for calculating the log_loss. This is then converted into a binary log string that called a **summary**, which is format readable for TensorBoard. The second line creates the corresponding FileWriter that is used to write the summaries to the log files in the directory.\n",
    "    \n",
    "**NOTE:** For the FileWriter, if the specified directory (i.e. `logdir`) does not actually exist, **it will automatically create the directory and the preceding parent directories if needed.** The directories specified in the FileWriter object are *relative* to where the current Python file is. Furthermore, the file to which the summaries are written to is also known as an **events file**.\n",
    "\n",
    "After the above modifications are made, we also need to revise the execution phase to evaluate the `logloss_summary` node during training. Again, this will result in a summary that can then in turn be written to the events file. Once all logs are recorded, it is then acceptable to close the FieWriter (i.e. at the end of the program).\n",
    "\n",
    "Let's update our code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_IN-45Q3eQZ",
    "outputId": "2ac37d83-838c-42eb-c544-27beaa4693d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tf_logs/run-20190210041621/'"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# function to create our log directories\n",
    "def get_logdir():\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    return  \"{}/run-{}/\".format(root_logdir, now)\n",
    "# run this cell to see how the format of our log folders read as\n",
    "get_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0L5dyMtW3eQa"
   },
   "outputs": [],
   "source": [
    "#################################### MODEL CONSTRUCTION ####################################\n",
    "tf.reset_default_graph()\n",
    "m, n = X_train.shape \n",
    "n_classes = len(np.unique(y_train))\n",
    "learning_rate = 0.01\n",
    "epsilon = 0.1 # to prevent underflow\n",
    "\n",
    "X = tf.placeholder(dtype=tf.float32, shape=(None, n), name='X')\n",
    "y = tf.placeholder(dtype=tf.int32, shape=(None), name='y')\n",
    "y_one_hot = tf.one_hot(y, n_classes)\n",
    "\n",
    "W = tf.get_variable(name='weights', shape=[n, n_classes], initializer=random_normal)\n",
    "logits = tf.matmul(X, W)\n",
    "y_proba = tf.nn.softmax(logits, name='predict')\n",
    "\n",
    "log_loss = tf.losses.softmax_cross_entropy(onehot_labels=y_one_hot, logits=logits)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(log_loss)\n",
    "init = tf.global_variables_initializer() \n",
    "saver = tf.train.Saver() \n",
    "\n",
    "# Add lines to write model to file\n",
    "logdir = get_logdir()\n",
    "loss_summary = tf.summary.scalar('log_loss', log_loss) \n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HyUzWGDa3eQb"
   },
   "source": [
    "Upon instantiation of `tf.summary.FileWriter`, we can see that TensorFlow immediately creates a file to the directory specified (i.e. in this case the directory is the out of the `get_logdir()` function). This is because on creation, the FileWriter object will create the **\"file stream\"** and continually write to it as the `save()` function is called. Thus, **it is important that you reset the graph on every new session to force a new file (i.e. log directory file) to be created. If not, multiple session runs will result in duplicate event files which is not what we want.**\n",
    "\n",
    "With this in mind, we will now run the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_OhOesm3eQc",
    "outputId": "5415836f-d5e2-4f1d-ad22-96ebb7603783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train Loss = 12.2022295 Validation Loss = 12.394914\n",
      "Epoch 250 Train Loss = 1.7059025 Validation Loss = 1.867842\n",
      "Epoch 500 Train Loss = 0.78918654 Validation Loss = 0.98245394\n",
      "Epoch 750 Train Loss = 0.49671638 Validation Loss = 0.7289132\n",
      "Epoch 1000 Train Loss = 0.36092353 Validation Loss = 0.6212871\n",
      "Epoch 1250 Train Loss = 0.28416026 Validation Loss = 0.5610999\n",
      "Epoch 1500 Train Loss = 0.23513268 Validation Loss = 0.5230874\n",
      "Epoch 1750 Train Loss = 0.20198353 Validation Loss = 0.4957424\n",
      "Epoch 2000 Train Loss = 0.17804828 Validation Loss = 0.47562137\n",
      "Epoch 2250 Train Loss = 0.15993229 Validation Loss = 0.4586993\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8497495826377296\n",
      "Confusion Matrix:\n",
      " [[164   0   1   2   0   2   5   1   3   0]\n",
      " [  0 150   5   0   6   1   4   4   6   6]\n",
      " [  2   5 155  11   1   0   1   1   1   0]\n",
      " [  0   4   0 151   0   4   0   2  12  10]\n",
      " [  2   3   0   0 169   0   1   3   1   2]\n",
      " [  2   4   2   3   0 165   0   1   1   4]\n",
      " [  1   3   0   0   2   4 170   0   1   0]\n",
      " [  3   0   1   4   3   0   0 164   4   0]\n",
      " [  0  15   5   9   2   7   4   5 112  15]\n",
      " [  5  10   0  12   3   8   2   5   8 127]]\n"
     ]
    }
   ],
   "source": [
    "# MAKE SURE YOU RUN MODEL CONSTRUCTION CELL BEFORE RUNNING THIS CELL\n",
    "def train_model(X_train, y_train, X_val, y_val, epochs=2500, batch_size=300, save_path='./models/my_softmax_model.model'):\n",
    "    # Open a session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Initialize loss values\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        # Initialize batch vALUES\n",
    "        m = len(X_train)\n",
    "        batches = int(m/batch_size)\n",
    "        \n",
    "        # Loop through the graph for n epochs\n",
    "        for epoch in range(epochs):\n",
    "            # Loop through the mini-batches\n",
    "            for batch in range(batches):\n",
    "                # Fetch a new batch\n",
    "                X_batch, y_batch = fetch_batch(batch_size)\n",
    "                # Run the training op\n",
    "                sess.run([training_op], feed_dict={X:X_batch, y:y_batch})\n",
    "                # Save outputs at every batch\n",
    "                summary_str = loss_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = (epoch+1) * (batch + 1)\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            # Get trianing/validation loss\n",
    "            train_loss = sess.run(log_loss, feed_dict={X:X_train, y:y_train})\n",
    "            val_loss = sess.run(log_loss, feed_dict={X:X_val, y:y_val})\n",
    "            # Save incremental loss values for visualization\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            # Save model and print results at 250 epochs\n",
    "            if epoch % 250 == 0:\n",
    "                saver.save(sess, save_path)\n",
    "                print(\"Epoch\", epoch, \"Train Loss =\", train_loss, \"Validation Loss =\", val_loss)\n",
    "        # Save final model\n",
    "        saver.save(sess, save_path)\n",
    "    # Plot loss values\n",
    "    plt.plot(train_losses, label='training loss')\n",
    "    plt.plot(val_losses, label='validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return updated weights\n",
    "    return W_update\n",
    "\n",
    "W_update = train_model(X_train, y_train, X_val, y_val)\n",
    "make_predictions(X_mnist, y_mnist, W_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5teUNcKv3eQe"
   },
   "source": [
    "## Accessing Tensorboard\n",
    "\n",
    "To begin, enter this code into the command line (make sure you are in the correct directory first):\n",
    "    \n",
    "    dir tf_logs\n",
    "    \n",
    "The code should give you a list of log file names in tf_logs, and each file should represent a unique model run (assuming you re-ran the construction phase of the code before running the training phase each time)! Now, to open Tensorboard all you have to do is enter the following code in your command line, entering 'tf_logs' directory as the '--logdir' argument:\n",
    "    \n",
    "    tensorboard --logdir tf_logs/\n",
    "    \n",
    "You should see something like this returned:\n",
    "    \n",
    "    TensorBoard 1.12.2 at http://CA47496-MCINI06:6006 (Press CTRL+C to quit)\n",
    "\n",
    "To open TensorBoard, all you have to do is copy and pase the linke provided into your browser.\n",
    "\n",
    "The **graphs** tab should look as follows:\n",
    "\n",
    "<img src='Module 9 images/c4_m9_p2_tb1.png' style=\"float:left;width:1000px;height:600;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0JHc9ydZ3eQf"
   },
   "source": [
    "The **scalers** tab should look as follows:\n",
    "\n",
    "<img src='Module 9 images/c4_m9_p2_tb2.png' style=\"float:left;width:1000px;height:600;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QmjphDub3eQf"
   },
   "source": [
    "## Improving you TensorBoard Output\n",
    "\n",
    "Lastly, we can improve upon our TensorBoard output by using name scopes. Using name scopes not only makes your code more readable, it also make the corresponding TensorBoard visualizations easier to follow. Tensorboard will essentially group all of the nodes from a single name scope into a bucket, which can make navigating a models architecture much simpler. See the code below for an example of what this could look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PoLl3WLx3eQg",
    "outputId": "69ffbcb0-71d7-440f-c74c-05acee27939b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train Loss = 12.4131365 Validation Loss = 12.572943\n",
      "Epoch 250 Train Loss = 1.5963033 Validation Loss = 1.7275982\n",
      "Epoch 500 Train Loss = 0.8345398 Validation Loss = 0.9931069\n",
      "Epoch 750 Train Loss = 0.55881095 Validation Loss = 0.7114693\n",
      "Epoch 1000 Train Loss = 0.41240004 Validation Loss = 0.5624761\n",
      "Epoch 1250 Train Loss = 0.32239437 Validation Loss = 0.46463266\n",
      "Epoch 1500 Train Loss = 0.26140845 Validation Loss = 0.39910907\n",
      "Epoch 1750 Train Loss = 0.2166153 Validation Loss = 0.35269657\n",
      "Epoch 2000 Train Loss = 0.18503301 Validation Loss = 0.32287103\n",
      "Epoch 2250 Train Loss = 0.16419493 Validation Loss = 0.30122072\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8497495826377296\n",
      "Confusion Matrix:\n",
      " [[164   0   1   2   0   2   5   1   3   0]\n",
      " [  0 150   5   0   6   1   4   4   6   6]\n",
      " [  2   5 155  11   1   0   1   1   1   0]\n",
      " [  0   4   0 151   0   4   0   2  12  10]\n",
      " [  2   3   0   0 169   0   1   3   1   2]\n",
      " [  2   4   2   3   0 165   0   1   1   4]\n",
      " [  1   3   0   0   2   4 170   0   1   0]\n",
      " [  3   0   1   4   3   0   0 164   4   0]\n",
      " [  0  15   5   9   2   7   4   5 112  15]\n",
      " [  5  10   0  12   3   8   2   5   8 127]]\n"
     ]
    }
   ],
   "source": [
    "#################################### MODEL CONSTRUCTION ####################################\n",
    "tf.reset_default_graph()\n",
    "m, n = X_train.shape \n",
    "n_classes = len(np.unique(y_train))\n",
    "learning_rate = 0.01\n",
    "epsilon = 0.1 # to prevent underflow\n",
    "\n",
    "with tf.variable_scope('INPUTS'):\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=(None, n), name='X')\n",
    "    y = tf.placeholder(dtype=tf.int32, shape=(None), name='y')\n",
    "    y_one_hot = tf.one_hot(y, n_classes)\n",
    "\n",
    "with tf.variable_scope('LINEAR_FORWARD'):\n",
    "    W = tf.get_variable(name='weights', shape=[n, n_classes], initializer=random_normal)\n",
    "    logits = tf.matmul(X, W, name='logits')\n",
    "    y_proba = tf.nn.softmax(logits, name='predictions') # Add in y_pred node so it can be called to make predictions\n",
    "\n",
    "with tf.variable_scope('LOSS_CALC'):\n",
    "    log_loss = tf.losses.softmax_cross_entropy(onehot_labels=y_one_hot, logits=logits)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(log_loss)\n",
    "\n",
    "logdir = get_logdir()\n",
    "with tf.variable_scope('SAVE'):\n",
    "    loss_summary = tf.summary.scalar('log_loss', log_loss) \n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "    saver = tf.train.Saver() \n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "\n",
    "#################################### MODEL EXECUTION ####################################\n",
    "def train_model(X_train, y_train, X_val, y_val, epochs=2500, batch_size=300, save_path='./models/my_softmax_model.model'):\n",
    "    # Open a session\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        # Initialize loss values\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        # Initialize batch vALUES\n",
    "        m = len(X_train)\n",
    "        batches = int(m/batch_size)\n",
    "        \n",
    "        # Loop through the graph for n epochs\n",
    "        for epoch in range(epochs):\n",
    "            # Loop through the mini-batches\n",
    "            for batch in range(batches):\n",
    "                # Fetch a new batch\n",
    "                X_batch, y_batch = fetch_batch(batch_size)\n",
    "                # Run the training op\n",
    "                sess.run([training_op], feed_dict={X:X_batch, y:y_batch})\n",
    "                # Save outputs at every batch\n",
    "                summary_str = loss_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = (epoch+1) * (batch + 1)\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            # Get trianing/validation loss\n",
    "            train_loss = sess.run(log_loss, feed_dict={X:X_train, y:y_train})\n",
    "            val_loss = sess.run(log_loss, feed_dict={X:X_val, y:y_val})\n",
    "            # Save incremental loss values for visualization\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            # Save model and print results at 250 epochs\n",
    "            if epoch % 250 == 0:\n",
    "                saver.save(sess, save_path)\n",
    "                print(\"Epoch\", epoch, \"Train Loss =\", train_loss, \"Validation Loss =\", val_loss)\n",
    "        # Save final model\n",
    "        saver.save(sess, save_path)\n",
    "    # Plot loss values\n",
    "    plt.plot(train_losses, label='training loss')\n",
    "    plt.plot(val_losses, label='validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return updated weights\n",
    "    return W_update\n",
    "\n",
    "W_update = train_model(X_train, y_train, X_val, y_val)\n",
    "make_predictions(X_mnist, y_mnist, W_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "igJJKzcz3eQi"
   },
   "source": [
    "The **graphs** tab should look like after we added variable scopes to our code:\n",
    "\n",
    "<img src='Module 9 images/c4_m9_p2_tb3.png' style=\"float:left;width:1000px;height:600;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End of Module.** \n",
    "\n",
    "You have reached the end of this module.\n",
    "If you have any questions, please reach out to your peers using the discussion boards. If you and your peers are unable to come to a suitable conclusion, do not hesitate to reach out to your instructor on the designated discussion board.\n",
    "When you are comfortable with the content, and have practiced to your satisfaction, you may proceed to any related assignments, and to the next module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-3PExnk3eQj"
   },
   "source": [
    "# References\n",
    "\n",
    "Géron, A. (2017). Chapter 9: Up and Running with TensorFlow and Chapter 10: Introduction to Artificial Neural Networks in Hands-On Machine Learning with Scikit-Learn and TensorFlow O’Reilly Media http://shop.oreilly.com/product/0636920052289.do![image.png](attachment:image.png)\n",
    "\n",
    "TensorFlow documentation and tutorials: https://www.tensorflow.org/tutorials\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplemental Material - TensorFlow2.0\n",
    "\n",
    "As the materials for this course were being created, the team at TensorFlow released **TensorFlow 2.0 (TF2)**, the second version of the package. \n",
    "\n",
    "Your knowledge of TensorFlow 1.0 (TF1) will still remain very important; nearly all TensorFlow models are still running on stable TF1 code, and much of the TensorFlow codebase remains that same. That said, there are some exciting updates in TF2 that can vastly improve the model building process and will likely become industry standard relatively quickly, so it’s important that you begin to understand these changes.\n",
    "\n",
    "Some of the major changes include:\n",
    "\n",
    "* **API cleanup**: Many APIs like tf.gans, tf.app, tf.contrib, tf.flags are either gone or moved to separate repositories.\n",
    "* **Eager Execution**: As you might recall, to build a Neural Net in TF1, we needed to define this abstract data structure called a Graph, and then to actually run the graph we needed to use an encapsulation called a Session. With eager execution, this changes. Now, TensorFlow code can be run like normal Python code. Meaning that operations are created and evaluated at once.\n",
    "* **Functions, not sessions**: A session.run() call is almost like a function call: You specify the inputs and the function to be called, and you get back a set of outputs. In TensorFlow 2.0, you can decorate a Python function using tf.function() to mark it for JIT compilation so that TensorFlow runs it as a single graph. That’s right, no more sessions!\n",
    "* **No more globals**: TensorFlow 1.0 relied heavily on implicitly global namespaces. When you called tf.Variable(), it would be put into the default graph, and it would remain there, even if you lost track of the Python variable pointing to it. You could then recover that tf.Variable, but only if you knew the name that it had been created with (which was often a huge pain). TensorFlow 2.0 eliminates all of these mechanisms in favor of the default mechanism: Keep track of your variables! If you lose track of a tf.Variable, it gets garbage collected (essentially erased from memory). The requirement to track variables creates some extra work for the user, but with Keras objects, the burden is minimized.\n",
    "* **Tight integration with Keras**: Keras is now the default and recommended high-level API for TensorFlow. The easiest way to train a model in TF 2.0 is by using the .fit() method on a Keras Sequential or Functional model (we cover Keras in more detail in the next module). This method is ideal for rapid prototyping for any type of model, and saves the user from having to tediously construct complicated model construction and execution pipelines.\n",
    "\n",
    "\n",
    "There are many more exciting changes in TF2, and you are encouraged to take a deep dive into all of them. To get started, take a look at the following sources:\n",
    "* TensorFlow 2.0 documentation: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf\n",
    "* The ‘Effective TensorFlow 2.0 Guide’, produced by the TensorFlow team: https://github.com/tensorflow/docs/blob/master/site/en/r2/guide/effective_tf2.md\n",
    "* Thalles Silva’s very thorough overview of the major changes in this HackerNoon article: https://hackernoon.com/everything-you-need-to-know-about-tensorflow-2-0-b0856960c074\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "TNc10gcJ3eQK",
    "ghLGtW7d3eQR"
   ],
   "name": "Module09_Part2_edited_by_ML_MC.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}